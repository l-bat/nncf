<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="4" skipped="741" tests="4393" time="1325.468" timestamp="2021-05-28T10:46:20.148091" hostname="nnlicv043"><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Conv2d-SymQuantization]" time="0.049" /><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Conv2d-AsymQuantization]" time="0.038" /><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Conv2d-Sparsity]" time="0.021" /><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Conv2d-MagnitudeSparsity]" time="0.020" /><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Conv2d-ConstSparsity]" time="0.020" /><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Linear-SymQuantization]" time="0.032" /><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Linear-AsymQuantization]" time="0.032" /><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Linear-Sparsity]" time="0.017" /><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Linear-MagnitudeSparsity]" time="0.016" /><testcase classname="tests.torch.test_algo_common.TestCompressionAlgos" name="test_can_export_compressed_model[Linear-ConstSparsity]" time="0.015" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[quantization0]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[quantization1]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[const_sparsity]" time="0.010" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[magnitude_sparsity]" time="0.012" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[rb_sparsity]" time="0.012" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[filter_pruning0]" time="0.012" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[filter_pruning1]" time="0.012" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[magnitude_sparsity_quantization0]" time="0.023" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[magnitude_sparsity_quantization1]" time="0.023" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[quantization_filter_pruning]" time="0.024" /><testcase classname="tests.torch.test_algo_common" name="test_can_get_compression_stage[magnitude_sparsity_quantization_filter_pruning]" time="0.026" /><testcase classname="tests.torch.test_algo_common" name="test_combo_of_compression_stages[CompressionStage.UNCOMPRESSED-CompressionStage.UNCOMPRESSED-CompressionStage.UNCOMPRESSED]" time="0.001" /><testcase classname="tests.torch.test_algo_common" name="test_combo_of_compression_stages[CompressionStage.PARTIALLY_COMPRESSED-CompressionStage.PARTIALLY_COMPRESSED-CompressionStage.PARTIALLY_COMPRESSED]" time="0.001" /><testcase classname="tests.torch.test_algo_common" name="test_combo_of_compression_stages[CompressionStage.FULLY_COMPRESSED-CompressionStage.FULLY_COMPRESSED-CompressionStage.FULLY_COMPRESSED]" time="0.001" /><testcase classname="tests.torch.test_algo_common" name="test_combo_of_compression_stages[CompressionStage.UNCOMPRESSED-CompressionStage.PARTIALLY_COMPRESSED-CompressionStage.PARTIALLY_COMPRESSED]" time="0.001" /><testcase classname="tests.torch.test_algo_common" name="test_combo_of_compression_stages[CompressionStage.UNCOMPRESSED-CompressionStage.FULLY_COMPRESSED-CompressionStage.PARTIALLY_COMPRESSED]" time="0.001" /><testcase classname="tests.torch.test_algo_common" name="test_combo_of_compression_stages[CompressionStage.PARTIALLY_COMPRESSED-CompressionStage.FULLY_COMPRESSED-CompressionStage.PARTIALLY_COMPRESSED]" time="0.001" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="1.953" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.036" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.036" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.036" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.036" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.036" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.036" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.036" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.035" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.034" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.033" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.161" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.055" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_magnitude_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_rb_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.050" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:quantization_const_sparsity__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:magnitude_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.062" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.053" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.053" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.048" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:rb_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_magnitude_sparsity-from:CPU_to:GPU-load_weights]" time="0.161" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_magnitude_sparsity-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_rb_sparsity-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_rb_sparsity-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:CPU-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_const_sparsity-from:CPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:quantization_const_sparsity-from:GPU_to:GPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:magnitude_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:magnitude_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:rb_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:rb_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.047" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:const_sparsity_quantization-from:CPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:CPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:CPU-load_weights]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:GPU-resume]" time="0.045" /><testcase classname="tests.torch.test_algo_common" name="test_load_state_interoperability[save:const_sparsity_quantization__load:const_sparsity_quantization-from:GPU_to:GPU-load_weights]" time="0.046" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-None-resume]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-None-load_weights]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-quantization-resume]" time="0.043" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-quantization-load_weights]" time="0.043" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-magnitude_sparsity-resume]" time="0.022" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-magnitude_sparsity-load_weights]" time="0.022" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-rb_sparsity-resume]" time="0.023" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-rb_sparsity-load_weights]" time="0.024" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-const_sparsity-resume]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:CPU-const_sparsity-load_weights]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-None-resume]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-None-load_weights]" time="0.020" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-quantization-resume]" time="0.043" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-quantization-load_weights]" time="0.043" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-magnitude_sparsity-resume]" time="0.022" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-magnitude_sparsity-load_weights]" time="0.023" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-rb_sparsity-resume]" time="0.023" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-rb_sparsity-load_weights]" time="0.023" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-const_sparsity-resume]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:CPU_to:GPU-const_sparsity-load_weights]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-None-resume]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-None-load_weights]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-quantization-resume]" time="0.043" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-quantization-load_weights]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-magnitude_sparsity-resume]" time="0.022" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-magnitude_sparsity-load_weights]" time="0.022" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-rb_sparsity-resume]" time="0.024" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-rb_sparsity-load_weights]" time="0.023" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-const_sparsity-resume]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:CPU-const_sparsity-load_weights]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-None-resume]" time="0.020" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-None-load_weights]" time="0.020" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-quantization-resume]" time="0.044" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-quantization-load_weights]" time="0.043" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-magnitude_sparsity-resume]" time="0.022" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-magnitude_sparsity-load_weights]" time="0.022" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-rb_sparsity-resume]" time="0.024" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-rb_sparsity-load_weights]" time="0.024" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-const_sparsity-resume]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_ordinary_load[from:GPU_to:GPU-const_sparsity-load_weights]" time="0.022" /><testcase classname="tests.torch.test_algo_common" name="test_can_export_compressed_model_with_input_output_names" time="0.049" /><testcase classname="tests.torch.test_algo_common" name="test_can_export_compressed_model_with_specified_domain_for_custom_ops" time="0.049" /><testcase classname="tests.torch.test_algo_common" name="test_compression_loss_gpu_device_compatibility[compression_rb_sparsity_quantization]" time="0.029" /><testcase classname="tests.torch.test_algo_common" name="test_compression_loss_gpu_device_compatibility[compression_quantization_rb_sparsity]" time="0.025" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[NoCompressionAlgorithmBuilder-CPU]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_algo_common.py:471: Skipped</skipped></testcase><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[NoCompressionAlgorithmBuilder-GPU]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_algo_common.py:471: Skipped</skipped></testcase><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[NoCompressionAlgorithmBuilder-VPU]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_algo_common.py:471: Skipped</skipped></testcase><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[quantization-CPU]" time="0.032" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[quantization-GPU]" time="0.031" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[quantization-VPU]" time="0.031" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[binarization-CPU]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[binarization-GPU]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[binarization-VPU]" time="0.021" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[const_sparsity-CPU]" time="0.017" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[const_sparsity-GPU]" time="0.017" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[const_sparsity-VPU]" time="0.018" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[magnitude_sparsity-CPU]" time="0.018" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[magnitude_sparsity-GPU]" time="0.018" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[magnitude_sparsity-VPU]" time="0.018" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[rb_sparsity-CPU]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[rb_sparsity-GPU]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[rb_sparsity-VPU]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[filter_pruning-CPU]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[filter_pruning-GPU]" time="0.019" /><testcase classname="tests.torch.test_algo_common" name="test_target_device_is_propagated_to_algos[filter_pruning-VPU]" time="0.023" /><testcase classname="tests.torch.test_api_behavior" name="test_range_init_is_called[precision_init_only]" time="0.046" /><testcase classname="tests.torch.test_api_behavior" name="test_range_init_is_called[no_init_params]" time="0.037" /><testcase classname="tests.torch.test_api_behavior" name="test_range_init_is_called[range_init_only]" time="0.037" /><testcase classname="tests.torch.test_api_behavior" name="test_range_init_is_called[skip_range_init]" time="0.040" /><testcase classname="tests.torch.test_api_behavior" name="test_model_is_inited_with_own_device_by_default[cpu]" time="0.081" /><testcase classname="tests.torch.test_api_behavior" name="test_model_is_inited_with_own_device_by_default[cuda]" time="0.086" /><testcase classname="tests.torch.test_api_behavior" name="test_model_is_inited_with_own_device_by_default[cuda:0]" time="0.086" /><testcase classname="tests.torch.test_api_behavior" name="test_model_is_inited_with_own_device_by_default[cuda:1]" time="1.915" /><testcase classname="tests.torch.test_backward_compat" name="test_model_can_be_loaded_with_resume[/home/liubov/nncf/tests/torch/data/configs/squeezenet1_1_cifar10_rb_sparsity_int8.json-gpu_dataparallel]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for backward compatibility testing is not set, use --backward-compat-models option.">/home/liubov/nncf/tests/torch/test_backward_compat.py:63: Path to models weights for backward compatibility testing is not set, use --backward-compat-models option.</skipped></testcase><testcase classname="tests.torch.test_backward_compat" name="test_loaded_model_evals_according_to_saved_acc[/home/liubov/nncf/tests/torch/data/configs/squeezenet1_1_cifar10_rb_sparsity_int8.json-gpu_dataparallel]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for backward compatibility testing is not set, use --backward-compat-models option.">/home/liubov/nncf/tests/torch/test_backward_compat.py:63: Path to models weights for backward compatibility testing is not set, use --backward-compat-models option.</skipped></testcase><testcase classname="tests.torch.test_backward_compat" name="test_model_can_be_loaded_with_resume[/home/liubov/nncf/tests/torch/data/configs/squeezenet1_1_cifar10_rb_sparsity_int8.json-multiprocessing_distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for backward compatibility testing is not set, use --backward-compat-models option.">/home/liubov/nncf/tests/torch/test_backward_compat.py:63: Path to models weights for backward compatibility testing is not set, use --backward-compat-models option.</skipped></testcase><testcase classname="tests.torch.test_backward_compat" name="test_loaded_model_evals_according_to_saved_acc[/home/liubov/nncf/tests/torch/data/configs/squeezenet1_1_cifar10_rb_sparsity_int8.json-multiprocessing_distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for backward compatibility testing is not set, use --backward-compat-models option.">/home/liubov/nncf/tests/torch/test_backward_compat.py:63: Path to models weights for backward compatibility testing is not set, use --backward-compat-models option.</skipped></testcase><testcase classname="tests.torch.test_backward_compat" name="test_renamed_activation_quantizer_storage_in_state_dict" time="0.022" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[alexnet]" time="0.208" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[lenet]" time="0.032" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[resnet18]" time="0.380" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[resnet50]" time="0.734" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[vgg16]" time="0.339" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[inception]" time="0.894" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[densenet121]" time="1.593" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[inception_v3]" time="2.539" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[squeezenet1_0]" time="0.321" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[squeezenet1_1]" time="0.188" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[shufflenetv2]" time="0.880" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[shuflenet_g2]" time="0.828" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[ssd_vgg]" time="0.727" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[ssd_mobilenet]" time="0.592" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[mobilenet_v2]" time="0.810" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[resnext29_32x4d]" time="0.436" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[pnasnetb]" time="1.238" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[senet18]" time="0.361" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[preresnet50]" time="0.841" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[unet]" time="0.548" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[lstm_cell]" time="0.167" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[lstm_uni_seq]" time="0.056" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[lstm_uni_stacked]" time="0.102" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[lstm_bi_seq]" time="0.099" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[lstm_bi_stacked]" time="0.313" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_build_graph[sr_small_model]" time="0.105" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-alexnet]" time="0.972" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-lenet]" time="0.096" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-resnet18]" time="0.865" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-resnet50]" time="2.286" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-vgg16]" time="0.674" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-inception]" time="2.317" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-densenet121]" time="4.433" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-inception_v3]" time="5.046" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-squeezenet1_0]" time="0.707" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-squeezenet1_1]" time="0.667" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-shufflenetv2]" time="1.949" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-shuflenet_g2]" time="1.792" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-ssd_vgg]" time="7.165" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-ssd_mobilenet]" time="2.967" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-mobilenet_v2]" time="1.955" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-resnext29_32x4d]" time="1.122" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-pnasnetb]" time="2.859" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-senet18]" time="1.208" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-preresnet50]" time="2.265" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-unet]" time="2.095" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-lstm_cell]" time="0.073" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-lstm_uni_seq]" time="0.127" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-lstm_uni_stacked]" time="0.362" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-lstm_bi_seq]" time="0.224" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-lstm_bi_stacked]" time="0.549" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[RB-sr_small_model]" time="0.425" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-alexnet]" time="2.562" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-lenet]" time="0.082" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-resnet18]" time="1.643" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-resnet50]" time="3.756" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-vgg16]" time="1.898" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-inception]" time="2.342" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-densenet121]" time="4.334" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-inception_v3]" time="6.461" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-squeezenet1_0]" time="0.527" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-squeezenet1_1]" time="0.694" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-shufflenetv2]" time="1.752" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-shuflenet_g2]" time="1.512" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-ssd_vgg]" time="9.065" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-ssd_mobilenet]" time="3.279" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-mobilenet_v2]" time="1.976" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-resnext29_32x4d]" time="1.220" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-pnasnetb]" time="2.559" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-senet18]" time="2.033" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-preresnet50]" time="3.717" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-unet]" time="4.251" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-lstm_cell]" time="0.066" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-lstm_uni_seq]" time="0.264" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-lstm_uni_stacked]" time="0.205" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-lstm_bi_seq]" time="0.325" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-lstm_bi_stacked]" time="0.377" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Magnitude-sr_small_model]" time="0.345" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-alexnet]" time="0.492" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-lenet]" time="0.075" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-resnet18]" time="0.682" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-resnet50]" time="1.645" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-vgg16]" time="0.617" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-inception]" time="1.952" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-densenet121]" time="3.593" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-inception_v3]" time="4.286" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-squeezenet1_0]" time="0.564" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-squeezenet1_1]" time="0.546" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-shufflenetv2]" time="1.725" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-shuflenet_g2]" time="1.446" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-ssd_vgg]" time="7.287" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-ssd_mobilenet]" time="2.549" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-mobilenet_v2]" time="1.686" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-resnext29_32x4d]" time="0.820" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-pnasnetb]" time="2.484" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-senet18]" time="0.949" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-preresnet50]" time="1.637" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-unet]" time="1.613" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-lstm_cell]" time="0.066" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-lstm_uni_seq]" time="0.114" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-lstm_uni_stacked]" time="0.339" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-lstm_bi_seq]" time="0.201" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-lstm_bi_stacked]" time="0.494" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_network[Const-sr_small_model]" time="0.219" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-alexnet]" time="0.664" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-lenet]" time="0.122" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-resnet18]" time="0.910" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-resnet50]" time="2.426" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-vgg16]" time="0.740" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-inception]" time="2.640" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-densenet121]" time="5.939" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-inception_v3]" time="5.619" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-squeezenet1_0]" time="0.821" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-squeezenet1_1]" time="0.787" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-shufflenetv2]" time="2.516" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-shuflenet_g2]" time="2.238" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-ssd_vgg]" time="7.182" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-ssd_mobilenet]" time="3.158" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-mobilenet_v2]" time="2.330" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-resnext29_32x4d]" time="1.316" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-pnasnetb]" time="3.958" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-senet18]" time="1.606" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-preresnet50]" time="2.474" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-unet]" time="1.775" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-lstm_cell]" time="0.281" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-lstm_uni_seq]" time="0.249" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-lstm_uni_stacked]" time="0.585" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-lstm_bi_seq]" time="0.456" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-lstm_bi_stacked]" time="1.142" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[symmetric-sr_small_model]" time="0.511" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-alexnet]" time="0.552" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-lenet]" time="0.134" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-resnet18]" time="0.975" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-resnet50]" time="2.552" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-vgg16]" time="0.775" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-inception]" time="2.784" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-densenet121]" time="6.430" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-inception_v3]" time="5.856" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-squeezenet1_0]" time="0.888" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-squeezenet1_1]" time="0.857" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-shufflenetv2]" time="2.655" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-shuflenet_g2]" time="2.403" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-ssd_vgg]" time="5.157" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-ssd_mobilenet]" time="2.844" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-mobilenet_v2]" time="2.493" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-resnext29_32x4d]" time="1.409" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-pnasnetb]" time="4.269" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-senet18]" time="1.605" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-preresnet50]" time="2.655" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-unet]" time="1.897" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-lstm_cell]" time="0.300" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-lstm_uni_seq]" time="0.312" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-lstm_uni_stacked]" time="0.706" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-lstm_bi_seq]" time="0.699" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-lstm_bi_stacked]" time="1.255" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_quantize_network[asymmetric-sr_small_model]" time="0.555" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[alexnet]" time="0.945" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[lenet]" time="0.164" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[resnet18]" time="1.336" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[resnet50]" time="3.316" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[vgg16]" time="0.903" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[inception]" time="3.577" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[densenet121]" time="7.409" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[inception_v3]" time="7.122" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[squeezenet1_0]" time="1.085" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[squeezenet1_1]" time="1.142" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[shufflenetv2]" time="3.011" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[shuflenet_g2]" time="2.698" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[ssd_vgg]" time="7.746" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[ssd_mobilenet]" time="3.611" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[mobilenet_v2]" time="3.166" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[resnext29_32x4d]" time="1.663" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[pnasnetb]" time="4.888" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[senet18]" time="2.054" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[preresnet50]" time="3.417" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[unet]" time="2.635" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[lstm_cell]" time="0.166" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[lstm_uni_seq]" time="0.417" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[lstm_uni_stacked]" time="0.513" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[lstm_bi_seq]" time="0.629" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[lstm_bi_stacked]" time="1.243" /><testcase classname="tests.torch.test_compressed_graph.TestModelsGraph" name="test_sparse_quantize_network[sr_small_model]" time="0.611" /><testcase classname="tests.torch.test_compressed_graph" name="test_gnmt_quantization[symmetric]" time="0.000"><skipped type="pytest.skip" message="Sporadic failures">/home/liubov/nncf/tests/torch/test_compressed_graph.py:366: Sporadic failures</skipped></testcase><testcase classname="tests.torch.test_compressed_graph" name="test_gnmt_quantization[asymmetric]" time="0.000"><skipped type="pytest.skip" message="Sporadic failures">/home/liubov/nncf/tests/torch/test_compressed_graph.py:366: Sporadic failures</skipped></testcase><testcase classname="tests.torch.test_compressed_graph" name="test_resnet18__with_not_qinput[symmetric]" time="0.900" /><testcase classname="tests.torch.test_compressed_graph" name="test_resnet18__with_not_qinput[asymmetric]" time="0.970" /><testcase classname="tests.torch.test_compressed_graph" name="test_resnet18__with_ignore[symmetric]" time="0.847" /><testcase classname="tests.torch.test_compressed_graph" name="test_resnet18__with_ignore[asymmetric]" time="0.887" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Conv1d]" time="0.038" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Conv2d]" time="0.038" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[ConvTranspose2d]" time="0.037" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Conv3d]" time="0.037" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[ConvTranspose3d]" time="0.038" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Linear]" time="0.036" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Embedding_module]" time="0.032" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[EmbeddingBag]" time="0.030" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Hardtanh]" time="0.166" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Tanh]" time="0.029" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[ELU]" time="0.028" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[PReLU]" time="0.028" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[LeakyReLU]" time="0.028" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[LayerNorm]" time="0.029" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[GELU]" time="0.028" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Sigmoid]" time="0.028" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Add]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__add__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__radd__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__iadd__]" time="0.035" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Sub]" time="0.019" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__sub__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__rsub__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__isub__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[torch_mul]" time="0.019" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[tensor_mul]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__mul__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__rmul__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__imul__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Div]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__div__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__idiv__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__truediv__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Exp]" time="0.027" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Erf]" time="0.028" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[MatMul0]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[BMM]" time="0.167" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[MatMul1]" time="0.036" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Mean]" time="0.017" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[round]" time="0.027" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Dropout]" time="0.024" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[Threshold]" time="0.024" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[BatchNorm1d]" time="0.029" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[BatchNorm2d]" time="0.029" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[BatchNorm3d]" time="0.029" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[AvgPool2d]" time="0.030" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[AdaptiveAvgPool2d]" time="0.031" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[AvgPool3d]" time="0.031" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[AdaptiveAvgPool3d]" time="0.031" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[MaxPool1d]" time="0.019" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[MaxPool2d]" time="0.026" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[MaxPool3d]" time="0.026" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[MaxUnpool3d]" time="0.031" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[pad]" time="0.025" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[cat]" time="0.029" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[stack]" time="0.029" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[relu]" time="0.025" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[relu_]" time="0.025" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[max]" time="0.026" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[min]" time="0.029" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[ArangeModel]" time="0.018" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[transpose]" time="0.023" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[TransposeModel]" time="0.029" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[GatherModel]" time="0.041" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[MaskedFillModel]" time="0.030" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[ReshapeModel]" time="0.054" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[contiguous]" time="0.020" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[split]" time="0.023" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[chunk]" time="0.023" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[expand]" time="0.023" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[embedding_function]" time="0.030" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[embedding_bag]" time="0.167" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[softmax]" time="0.024" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__lt__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__le__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__gt__]" time="0.034" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__mod__]" time="0.035" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__eq__]" time="0.035" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__ne__]" time="0.035" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__or__]" time="0.027" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__xor__]" time="0.026" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__and__]" time="0.026" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[logical_not_]" time="0.028" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[__pow__]" time="0.035" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[interpolate]" time="0.023" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[repeat_interleave]" time="0.024" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[clone]" time="0.020" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[pixel_shuffle]" time="0.028" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[ManyNonEvalModules]" time="0.080" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[EmbeddingSumModel]" time="0.047" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[EmbeddingCatLinearModel]" time="0.056" /><testcase classname="tests.torch.test_compressed_graph" name="test_synthetic_model_quantization[MultiOutputSameTensorModel]" time="0.037" /><testcase classname="tests.torch.test_compressed_graph" name="test_output_quantization[symmetric]" time="1.794" /><testcase classname="tests.torch.test_compressed_graph" name="test_output_quantization[asymmetric]" time="2.009" /><testcase classname="tests.torch.test_compressed_graph" name="test_custom_quantizable_subgraph_patterns[symmetric]" time="1.567" /><testcase classname="tests.torch.test_compressed_graph" name="test_custom_quantizable_subgraph_patterns[asymmetric]" time="1.696" /><testcase classname="tests.torch.test_compressed_graph" name="test_compressed_graph_models_hw[HWConfigType.CPU-resnet50]" time="1.565" /><testcase classname="tests.torch.test_compressed_graph" name="test_compressed_graph_models_hw[HWConfigType.CPU-inception_v3]" time="4.121" /><testcase classname="tests.torch.test_compressed_graph" name="test_compressed_graph_models_hw[HWConfigType.CPU-mobilenet_v2]" time="1.687" /><testcase classname="tests.torch.test_compressed_graph" name="test_compressed_graph_models_hw[HWConfigType.GPU-resnet50]" time="1.581" /><testcase classname="tests.torch.test_compressed_graph" name="test_compressed_graph_models_hw[HWConfigType.GPU-inception_v3]" time="4.141" /><testcase classname="tests.torch.test_compressed_graph" name="test_compressed_graph_models_hw[HWConfigType.GPU-mobilenet_v2]" time="1.576" /><testcase classname="tests.torch.test_compressed_graph" name="test_compressed_graph_models_hw[HWConfigType.VPU-resnet50]" time="1.690" /><testcase classname="tests.torch.test_compressed_graph" name="test_compressed_graph_models_hw[HWConfigType.VPU-inception_v3]" time="3.982" /><testcase classname="tests.torch.test_compressed_graph" name="test_compressed_graph_models_hw[HWConfigType.VPU-mobilenet_v2]" time="1.678" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params0]" time="0.124" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params1]" time="0.123" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params2]" time="0.123" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params3]" time="0.123" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params4]" time="0.123" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params5]" time="0.123" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params6]" time="0.122" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params7]" time="0.093" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params8]" time="0.094" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params9]" time="0.094" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params10]" time="0.093" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params11]" time="0.094" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params12]" time="0.094" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params13]" time="0.032" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params14]" time="0.032" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params15]" time="0.032" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params16]" time="0.032" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params17]" time="0.033" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params18]" time="0.031" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params19]" time="0.032" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params20]" time="0.032" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params21]" time="0.033" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params22]" time="0.032" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params23]" time="0.032" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_algorithms_add_params[configs_building_params24]" time="0.032" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params0]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params1]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params2]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params3]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params4]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params5]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params6]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params7]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params8]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params9]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params10]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params11]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params12]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params13]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params14]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params15]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params16]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params17]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params18]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params19]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params20]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params21]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params22]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params23]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params24]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params25]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params26]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params27]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params28]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params29]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params30]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params31]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params32]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params33]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params34]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params35]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params36]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params37]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params38]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params39]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params40]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params41]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params42]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_parameter_is_initialized_correctly[one_parameter_model_creation_params43]" time="0.001" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params0]" time="0.273" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params1]" time="0.272" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params2]" time="0.272" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params3]" time="0.271" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params4]" time="0.272" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params5]" time="0.424" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params6]" time="0.272" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params7]" time="0.205" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params8]" time="0.204" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params9]" time="0.205" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params10]" time="0.205" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params11]" time="0.204" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params12]" time="0.205" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params13]" time="0.078" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params14]" time="0.077" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params15]" time="0.079" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params16]" time="0.077" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params17]" time="0.077" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params18]" time="0.078" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params19]" time="0.075" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params20]" time="0.076" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params21]" time="0.075" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params22]" time="0.075" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params23]" time="0.076" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_multiplies_grads_values[configs_building_params24]" time="0.075" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params0]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params1]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params2]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params3]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params4]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params5]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params6]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params7]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params8]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params9]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params10]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params11]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params12]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params13]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params14]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params15]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params16]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params17]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params18]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params19]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params20]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params21]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params22]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params23]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params24]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params25]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params26]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params27]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params28]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params29]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params30]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params31]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params32]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params33]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params34]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params35]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params36]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params37]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_multiplies_grads_values[one_parameter_model_creation_params38]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params0]" time="0.286" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params1]" time="0.315" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params2]" time="0.315" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params3]" time="0.313" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params4]" time="0.313" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params5]" time="0.312" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params6]" time="0.314" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params7]" time="0.361" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params8]" time="0.229" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params9]" time="0.229" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params10]" time="0.228" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params11]" time="0.229" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params12]" time="0.229" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params13]" time="0.118" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params14]" time="0.118" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params15]" time="0.118" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params16]" time="0.118" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params17]" time="0.118" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params18]" time="0.117" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params19]" time="0.097" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params20]" time="0.097" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params21]" time="0.097" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params22]" time="0.097" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params23]" time="0.097" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multipliers_in_config_affect_training_speed[configs_building_params24]" time="0.097" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params0]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params1]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params2]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params3]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params4]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params5]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params6]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params7]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params8]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params9]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params10]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params11]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params12]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params13]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params14]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params15]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params16]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params17]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params18]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params19]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params20]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params21]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params22]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params23]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params24]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params25]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params26]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params27]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params28]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params29]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params30]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params31]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params32]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params33]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params34]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params35]" time="0.004" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params36]" time="0.003" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params37]" time="0.002" /><testcase classname="tests.torch.test_compression_lr_multiplier" name="test_if_setting_multiplier_in_parameter_affect_training_speed[one_parameter_model_creation_params38]" time="0.004" /><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-mobilenet_v2_sym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-mobilenet_v2_sym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-mobilenet_v2_sym_int8-multiprocessing-distributed] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-mobilenet_v2_sym_int8-multiprocessing-distributed] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-mobilenet_v2_asym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-mobilenet_v2_asym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-mobilenet_v2_asym_int8-multiprocessing-distributed] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-mobilenet_v2_asym_int8-multiprocessing-distributed] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-mobilenet_v2_asym_int8-cpu-only]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-mobilenet_v2_asym_int8-cpu-only]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-mobilenet_v2_asym_int8-cpu-only] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-mobilenet_v2_asym_int8-cpu-only] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-inceptionV3_int8-]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-inceptionV3_int8-]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-inceptionV3_int8-] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-inceptionV3_int8-] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-resnet50_int8-]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-resnet50_int8-]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-resnet50_int8-] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-resnet50_int8-] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-mobilenet_v2_magnitude_sparsity_int8-]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-mobilenet_v2_magnitude_sparsity_int8-]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-mobilenet_v2_magnitude_sparsity_int8-] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-mobilenet_v2_magnitude_sparsity_int8-] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-mobilenet_v2_magnitude_sparsity_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-mobilenet_v2_magnitude_sparsity_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-mobilenet_v2_magnitude_sparsity_int8-multiprocessing-distributed] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-mobilenet_v2_magnitude_sparsity_int8-multiprocessing-distributed] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-mobilenet_v2_rb_sparsity_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-mobilenet_v2_rb_sparsity_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-mobilenet_v2_rb_sparsity_int8-multiprocessing-distributed] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-mobilenet_v2_rb_sparsity_int8-multiprocessing-distributed] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-mobilenet_v2_imagenet_sym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-mobilenet_v2_imagenet_sym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-mobilenet_v2_imagenet_sym_int8-multiprocessing-distributed] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-mobilenet_v2_imagenet_sym_int8-multiprocessing-distributed] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-mobilenet_v2_imagenet_asym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-mobilenet_v2_imagenet_asym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-mobilenet_v2_imagenet_asym_int8-multiprocessing-distributed] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-mobilenet_v2_imagenet_asym_int8-multiprocessing-distributed] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-resnet50_imagenet_sym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-resnet50_imagenet_sym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-resnet50_imagenet_sym_int8-multiprocessing-distributed] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-resnet50_imagenet_sym_int8-multiprocessing-distributed] depends on train</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_train[classification-resnet50_imagenet_asym_int8-multiprocessing-distributed]" time="0.000"><skipped type="pytest.skip" message="Path to models weights for weekly testing is not set, use --weekly-models option.">/home/liubov/nncf/tests/torch/test_compression_training.py:182: Path to models weights for weekly testing is not set, use --weekly-models option.</skipped></testcase><testcase classname="tests.torch.test_compression_training" name="test_compression_eval_trained[classification-resnet50_imagenet_asym_int8-multiprocessing-distributed]" time="0.001"><skipped type="pytest.skip" message="test_compression_eval_trained[classification-resnet50_imagenet_asym_int8-multiprocessing-distributed] depends on train">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_compression_eval_trained[classification-resnet50_imagenet_asym_int8-multiprocessing-distributed] depends on train</skipped></testcase><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/resnet50_imagenet.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/rmnet_cifar_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/inception_v3_imagenet_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/mobilenet_v2_cifar100.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/mobilenet_v2_imagenet_int8_per_tensor.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/mobilenet_v2_imagenet.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/squeezenet1_1_imagenet_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/mobilenetv3_imagenet_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/mobilenet_v2_imagenet_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/squeezenet1_1_imagenet.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/resnet50_imagenet_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/inception_v3_imagenet.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/squeezenet1_1_imagenet_int8_per_tensor.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/densenet161_imagenet_custom_quant_pattern.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/resnet50_imagenet_int8_per_tensor.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/quantization/mobilenet_v2_cifar100_asym_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity_quantization/mobilenet_v2_imagenet_rb_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity_quantization/inception_v3_imagenet_rb_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity_quantization/resnet50_imagenet_rb_sparsity50_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity_quantization/resnet34_cifar_rb_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity_quantization/resnet50_imagenet_rb_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/pruning/resnet18_pruning_geometric_median.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/pruning/resnet18_pruning_magnitude.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/pruning/resnet34_imagenet.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/pruning/googlenet_pruning_geometric_median.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/pruning/resnet50_pruning_geometric_median.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/pruning/googlenet_imagenet.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/pruning/resnet34_pruning_geometric_median.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/binarization/resnet18_imagenet_binarization_dorefa.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/binarization/resnet18_imagenet.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/binarization/resnet18_imagenet_binarization_xnor.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/resnet50_imagenet_mixed_int_autoq_staged.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/resnet50_imagenet_mixed_int_manual_staged.json]" time="0.012" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/squeezenet1_1_imagenet_mixed_int_manual.json]" time="0.010" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/mobilenet_v2_imagenet_mixed_int_manual.json]" time="0.013" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/resnet50_imagenet_mixed_int_manual.json]" time="0.013" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/squeezenet1_1_imagenet_mixed_int_hawq.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/squeezenet1_1_imagenet_mixed_int_manual_staged.json]" time="0.010" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/resnet50_imagenet_mixed_int_hawq.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/mobilenet_v2_imagenet_mixed_int_manual_staged.json]" time="0.013" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/mobilenet_v2_imagenet_mixed_int_autoq_staged.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/mixed_precision/mobilenet_v2_imagenet_mixed_int_hawq.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity/mobilenet_v2_imagenet_const_sparsity.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity/resnet34_cifar_rb_sparsity.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity/resnet34_cifar_magnitude_sparsity.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity/resnet50_imagenet_rb_sparsity.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity/mobilenet_v2_imagenet_rb_sparsity.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/classification/configs/sparsity/inception_v3_imagenet_rb_sparsity.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/icnet_cityscapes.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_mapillary.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/icnet_camvid_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_camvid_bin_xnor.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_mapillary_magnitude_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_camvid_magnitude_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_mapillary_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_cityscapes.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/icnet_camvid.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_voc.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_camvid_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_camvid_rb_sparsity.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/icnet_camvid_magnitude_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_mapillary_magnitude_sparsity.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_camvid.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/semantic_segmentation/configs/unet_mapillary_pruning_geometric_median.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd512_vgg_voc_magnitude_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd300_mobilenet_voc.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd300_vgg_voc_magnitude_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd512_vgg_voc.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd512_vgg_voc_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd300_vgg_voc.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd300_vgg_voc_pruning_geometric_median.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd300_mobilenet_voc_rb_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd300_vgg_voc_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[examples/torch/object_detection/configs/ssd300_mobilenet_voc_magnitude_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/resnet18_cifar10_staged_quant.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/resnet18_cifar100_bin_xnor.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/resnet18_pruning_magnitude.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/squeezenet1_1_cifar10_rb_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/unet_camvid_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/unet_camvid_rb_sparsity.json]" time="0.007" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/ssd300_vgg_voc_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/inception_v3_mock_dataset.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/cifar100/mobilenet_v2_sym_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/cifar100/mobilenet_v2_magnitude_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/cifar100/mobilenet_v2_asym_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/cifar100/mobilenet_v2_finetune.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/cifar100/inceptionV3_finetune.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/cifar100/mobilenet_v2_rb_sparsity_int8.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/cifar100/inceptionV3_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/cifar100/resnet50_finetune.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/cifar100/resnet50_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/imagenet/resnet50_imagenet_asym_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/imagenet/mobilenet_v2_imagenet_asym_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/imagenet/resnet50_imagenet_sym_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/weekly/classification/imagenet/mobilenet_v2_imagenet_sym_int8.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/hawq/resnet18_cifar10_mixed_int.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/hawq/unet_camvid_mixed_int.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/hawq/resnet18_cifar10_mixed_int_manual.json]" time="0.010" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/hawq/inception_v3_cifar10_mixed_int.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/hawq/ssd300_vgg_voc_mixed_int.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/configs/hawq/icnet_camvid_mixed_int.json]" time="0.008" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/schema_validation_bad_configs/bad_algo_name.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/schema_validation_bad_configs/params_mismatch.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/schema_validation_bad_configs/no_inputinfo.json]" time="0.006" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/schema_validation_bad_configs/wrong_num_init_steps_placement.json]" time="0.011" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/schema_validation_bad_configs/hawq_bitwidth_per_scope_format_mismatch.json]" time="0.009" /><testcase classname="tests.torch.test_config_schema" name="test_json_against_nncf_config_schema[tests/torch/data/schema_validation_bad_configs/empty_config.json]" time="0.006" /><testcase classname="tests.torch.test_context_independence" name="test_context_independence[symmetric-model_name0-model_builder0-input_size0]" time="0.795" /><testcase classname="tests.torch.test_context_independence" name="test_context_independence[asymmetric-model_name0-model_builder0-input_size0]" time="0.682" /><testcase classname="tests.torch.test_distributed_data_parallel_mode" name="test_is_ddp_freezing[20.0]" time="0.058"><failure message="_pickle.PicklingError: Can't pickle &lt;function worker at 0x7fef8ab99af0&gt;: it's not the same object as test_distributed_data_parallel_mode.worker">waiting_time = 20.0

    @pytest.mark.parametrize('waiting_time', [20.0])
    def test_is_ddp_freezing(waiting_time: float) -&gt; None:
        # Number of processes the same as GPU count
        n_procs = torch.cuda.device_count()
&gt;       ctx = mp.spawn(fn=worker, args=(n_procs,), nprocs=n_procs, join=False)

test_distributed_data_parallel_mode.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:230: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
../../../miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:179: in start_processes
    process.start()
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/popen_spawn_posix.py:47: in _launch
    reduction.dump(process_obj, fp)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;SpawnProcess name='SpawnProcess-1' parent=4258 initial&gt;, file = &lt;_io.BytesIO object at 0x7fef5d7e27c0&gt;, protocol = None

    def dump(obj, file, protocol=None):
        '''Replacement for pickle.dump() using ForkingPickler.'''
&gt;       ForkingPickler(file, protocol).dump(obj)
E       _pickle.PicklingError: Can't pickle &lt;function worker at 0x7fef8ab99af0&gt;: it's not the same object as test_distributed_data_parallel_mode.worker

../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/reduction.py:60: PicklingError</failure></testcase><testcase classname="tests.torch.test_extensions_build" name="test_force_cuda_build[venv-develop-GPU]" time="124.055" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[no_compression]" time="0.015" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[8_bits_quantization]" time="0.066" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[8_bits_quantization_all_frozen]" time="0.060" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[8_bits_quantization_with_frozen_not_wrapped]" time="0.042" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[8_bits_quantization_with_frozen_in_ignored_scope]" time="0.042" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[8_bits_quantization_with_frozen_in_ignored_nncf_scope]" time="0.042" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[8_bits_quantization_with_not_all_frozen_in_ignored_scope]" time="0.041" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[mixed_precision_quantization]" time="0.057" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[mixed_precision_quantization_with_frozen_not_wrapped]" time="0.058" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[mixed_precision_quantization_with_frozen_in_ignored_scope]" time="0.057" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[mixed_precision_quantization_with_not_all_frozen_in_ignored_scope]" time="0.054" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[mixed_precision_quantization_with_frozen_in_target_scope]" time="0.052" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[4_bits_quantization]" time="0.039" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[4_bits_quantization_with_frozen_in_ignored_scope]" time="0.041" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[4_bits_quantization_with_not_all_frozen_in_ignored_scope]" time="0.045" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[magnitude_sparsity]" time="0.016" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[rb_sparsity]" time="0.017" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[rb_sparsity_8_bits_quantization_with_frozen]" time="0.038" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[rb_sparsity_8_bits_quantization_with_frozen_sparsity_in_ignored_scope]" time="0.066" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[const_sparsity]" time="0.019" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[const_sparsity_8_bits_quantization]" time="0.065" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[const_sparsity_4_bits_quantization]" time="0.047" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[const_sparsity_4_bits_quantization_with_frozen_int4_in_ignored_scope]" time="0.044" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[rb_sparsity_4_bits_quantization]" time="0.027" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[rb_sparsity_4_bits_quantization_with_int4_ignored]" time="0.027" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[rb_sparsity_4_bits_quantization_with_frozen_in_ignored_scope]" time="0.045" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[filter_pruning_with_frozen_in_ignored_scope0]" time="0.016" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[filter_pruning_with_frozen_in_ignored_scope1]" time="0.012" /><testcase classname="tests.torch.test_frozen_layers" name="test_frozen_layers[binarization]" time="0.013" /><testcase classname="tests.torch.test_graph_analysis" name="test_graph_pattern_io_building" time="0.001" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_dynamic_graph_does_not_inflate_during_multiple_forwards[default]" time="0.128" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_dynamic_graph_does_not_inflate_during_multiple_forwards[user_dummy]" time="0.127" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_dynamic_graph_does_not_inflate_during_multiple_forwards[user_wrap_inputs_fn]" time="0.126" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_dynamic_graph_is_the_same_after_export[default]" time="0.110" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_dynamic_graph_is_the_same_after_export[user_dummy]" time="0.108" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_dynamic_graph_is_the_same_after_export[user_wrap_inputs_fn]" time="0.107" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_dummy_forwards_do_not_inflate_dynamic_graph[default]" time="0.057" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_dummy_forwards_do_not_inflate_dynamic_graph[user_dummy]" time="0.056" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_dummy_forwards_do_not_inflate_dynamic_graph[user_wrap_inputs_fn]" time="0.056" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_compressed_graph_with_user_wrap_fn" time="0.094" /><testcase classname="tests.torch.test_graph_building.TestGraphStability" name="test_compressed_graph_with_user_dummy_forward" time="0.094" /><testcase classname="tests.torch.test_graph_building" name="test_no_nncf_trace_context_manager" time="0.000" /><testcase classname="tests.torch.test_graph_building" name="test_ambiguous_function" time="0.002" /><testcase classname="tests.torch.test_graph_building" name="test_forward_trace_functor" time="0.001" /><testcase classname="tests.torch.test_graph_building" name="test_activation_shape_tracing[input_shape0]" time="0.006" /><testcase classname="tests.torch.test_graph_building" name="test_activation_shape_tracing[input_shape1]" time="0.008" /><testcase classname="tests.torch.test_graph_building" name="test_activation_shape_tracing[input_shape2]" time="0.019" /><testcase classname="tests.torch.test_graph_building" name="test_input_info_specification_from_config[input_info_test_struct0]" time="0.017" /><testcase classname="tests.torch.test_graph_building" name="test_input_info_specification_from_config[input_info_test_struct1]" time="0.015" /><testcase classname="tests.torch.test_graph_building" name="test_input_info_specification_from_config[input_info_test_struct2]" time="0.015" /><testcase classname="tests.torch.test_graph_building" name="test_input_info_specification_from_config[input_info_test_struct3]" time="0.016" /><testcase classname="tests.torch.test_graph_building" name="test_struct_auxiliary_nodes_ptnncf_graph" time="0.047" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_module_by_node_name__for_non_nested_module" time="0.001" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_module_by_node_name__for_nested_module" time="0.001" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_all_layers_by_type__for_standard_type" time="0.001" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_all_layers_by_type__for_multiple_type" time="0.001" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_all_layers_by_type__for_not_exact_type" time="0.001" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_all_layers_by_type__for_subtype" time="0.001" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_all_layers_by_type__with_ignored_scope[single]" time="0.002" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_all_layers_by_type__with_ignored_scope[multiple]" time="0.002" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_all_layers_by_type__with_ignored_scope[common]" time="0.002" /><testcase classname="tests.torch.test_graph_iterator" name="test_set_module_by_node_name__for_non_nested_module" time="0.001" /><testcase classname="tests.torch.test_graph_iterator" name="test_set_module_by_node_name__for_nested_module" time="0.001" /><testcase classname="tests.torch.test_graph_iterator" name="test_get_all_nodes" time="0.005" /><testcase classname="tests.torch.test_graph_iterator" name="test_apply_by_node_name" time="0.001" /><testcase classname="tests.torch.test_graph_iterator" name="test_parse_node_name" time="0.000" /><testcase classname="tests.torch.test_helpers" name="test_basic_model_has_expected_params" time="0.001" /><testcase classname="tests.torch.test_helpers" name="test_basic_model_is_valid" time="0.001" /><testcase classname="tests.torch.test_helpers" name="test_two_conv_model_has_expected_params" time="0.001" /><testcase classname="tests.torch.test_helpers" name="test_two_conv_model_is_valid" time="0.001" /><testcase classname="tests.torch.test_init_data_loader" name="test_can_create_partial_dataloader__with_defaults" time="0.000" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_invalid_ratio[string]" time="0.000" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_invalid_ratio[0.5]" time="0.000" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_invalid_ratio[-17]" time="0.000" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_invalid_ratio[-0.01]" time="0.000" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_invalid_ratio[1.01]" time="0.000" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_invalid_ratio[5]" time="0.000" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_invalid_ratio[100]" time="0.000" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_valid_ratio[0.0]" time="0.001" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_valid_ratio[0.05]" time="0.001" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_valid_ratio[0.2]" time="0.001" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_valid_ratio[0.51]" time="0.001" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_valid_ratio[0.89]" time="0.001" /><testcase classname="tests.torch.test_init_data_loader" name="test_partial_dataloader__with_valid_ratio[1.0]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct0]" time="0.002" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct1]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct2]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct3]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct4]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct5]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct6]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct7]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct8]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_input_wrapper_wrap_inputs[inputs_test_struct9]" time="0.001" /><testcase classname="tests.torch.test_input_management" name="test_same_input_tensor_replication" time="0.020" /><testcase classname="tests.torch.test_install" name="test_install[install-virtualenv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[install-venv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[develop-virtualenv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[develop-venv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[sdist-virtualenv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[sdist-venv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[bdist_wheel-virtualenv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[bdist_wheel-venv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[pip_pypi-virtualenv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[pip_pypi-venv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[pip_local-virtualenv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[pip_local-venv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[pip_e_local-virtualenv]" time="0.001"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_install" name="test_install[pip_e_local-venv]" time="0.002"><skipped type="pytest.skip" message="Please specify type of installation">/home/liubov/nncf/tests/torch/conftest.py:172: Please specify type of installation</skipped></testcase><testcase classname="tests.torch.test_load_model" name="test_export_sq_11_is_ok" time="0.312" /><testcase classname="tests.torch.test_load_model" name="test_load_state_skips_not_matched_params__from_larger_to_smaller" time="0.002" /><testcase classname="tests.torch.test_load_model" name="test_can_skip_padding_value" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_can_load_padding_value" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_load_state_skips_not_matched_params__from_smaller_to_larger" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1__TO__1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1__TO__1]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1-2__TO__1-2-3]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1-2-4__TO__1-2-3]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1-2__TO__1-2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1-2__TO__1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1__TO__1-2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1__TO__1-2]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.1-nncf_module.2__TO__1-2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1-2__TO__module.1-nncf_module.2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.nncf_module.1-module.2__TO__1-nncf_module.2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.nncf_module.1.1-module.2__TO__1-2.2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[pre_ops.0.op.1-pre_ops.1.op.2__TO__pre_ops.1.op.1-pre_ops.0.op.2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[pre_ops.0.op.1-pre_ops.1.op.1__TO__pre_ops.0.op.1-pre_ops.1.op.1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[nncf_module.pre_ops.1.op.1-nncf_module.pre_ops.0.op.1__TO__module.nncf_module.pre_ops.1.op.1-module.nncf_module.pre_ops.0.op.1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[pre_ops.0.op.1-pre_ops.1.op.2__TO__pre_ops.1.op.1-pre_ops.1.op.2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.1-1__TO__module.1-1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.1-1__TO__module.1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[pre_ops.0.op.1-module.pre_ops.1.op.2__TO__module.pre_ops.0.op.1|OUTPUT-pre_ops.6.op.2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.1__TO__module.1-1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1__TO__module.1-1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[1-module.1__TO__1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[activation_quantizers.RELU_0.op1-activation_quantizers.RELU_0.op2__TO__external_quantizers.RELU_0.op1-external_quantizers.RELU_0.op2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[RELU_0.op1-RELU_0.op2__TO__RELU_0|OUTPUT.op1-RELU_0|INPUT.op2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[activation_quantizers.RELU_0.op1-activation_quantizers.RELU_0.op2__TO__external_quantizers.RELU_0|OUTPUT.op1-external_quantizers.RELU_0|INPUT.op2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.activation_quantizers.RELU_0.op1-module.activation_quantizers.RELU_1.op1__TO__external_quantizers.RELU_0|OUTPUT;RELU_1|OUTPUT.op1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.external_quantizers.RELU_0.op1-module.external_quantizers.RELU_1.op1__TO__external_quantizers.RELU_0|OUTPUT;RELU_1|OUTPUT.op1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.external_quantizers.RELU_0.op1-module.external_quantizers.RELU_1.op1-module.external_quantizers.RELU_2.op1__TO__external_quantizers.RELU_0|OUTPUT;RELU_2|OUTPUT;RELU_1|OUTPUT.op1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.external_quantizers.RELU_0.op1-module.external_quantizers.RELU_1.op2-module.external_quantizers.RELU_2.prx_op1__TO__external_quantizers.RELU_0|OUTPUT;RELU_2|OUTPUT;RELU_1|OUTPUT.op1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[module.external_quantizers.RELU_0.op1-module.external_quantizers.RELU_3.op1-module.external_quantizers.RELU_2.op1__TO__external_quantizers.RELU_0|OUTPUT;RELU_2|OUTPUT;RELU_1|OUTPUT.op1__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[op1.sfx__TO__op1.sfx-prx.op1-prx.op2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[op1.sfx-prx.op2.sfx__TO__op1.sfx-prx.op1-prx.op2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[op1.sfx__TO__op1.sfx-prx.op1-prx.op2-prx.op2.sfx__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[op1.sfx-prx.op1-prx.op2__TO__op1.sfx-prx.op1-prx.op2.sfx__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[op1.sfx__TO__op1.sfx-prx_op1-prx_op2__resume]" time="0.001" /><testcase classname="tests.torch.test_load_model" name="test_match_key[op1.sfx-prx_op1-prx_op2__TO__op1.sfx-prx_op1-prx.op2.sfx__resume]" time="0.001" /><testcase classname="tests.torch.test_matcher" name="test_simple" time="0.001" /><testcase classname="tests.torch.test_matcher" name="test_two_matched" time="0.001" /><testcase classname="tests.torch.test_matcher" name="test_graph_branching" time="0.001" /><testcase classname="tests.torch.test_matcher" name="test_graph_branching_other_order" time="0.001" /><testcase classname="tests.torch.test_matcher" name="test_alternating" time="0.000" /><testcase classname="tests.torch.test_matcher" name="test_alternating_longest" time="0.001" /><testcase classname="tests.torch.test_matcher" name="test_branching_expression" time="0.001" /><testcase classname="tests.torch.test_matcher" name="test_branching_expression3" time="0.001" /><testcase classname="tests.torch.test_matcher" name="test_branching_expression2" time="0.001" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point0]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point1]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point2]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point3]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point4]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point5]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point6]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point7]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point8]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_single_insertions[target_point9]" time="0.006" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[LAYER-same]" time="0.005"><skipped type="pytest.skip" message="Insertion type TargetType.LAYER currently unsupported in PT">/home/liubov/nncf/tests/torch/test_nncf_network.py:300: Insertion type TargetType.LAYER currently unsupported in PT</skipped></testcase><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[BEFORE_LAYER-same]" time="0.005"><skipped type="pytest.skip" message="Insertion type TargetType.BEFORE_LAYER currently unsupported in PT">/home/liubov/nncf/tests/torch/test_nncf_network.py:300: Insertion type TargetType.BEFORE_LAYER currently unsupported in PT</skipped></testcase><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[AFTER_LAYER-same]" time="0.005"><skipped type="pytest.skip" message="Insertion type TargetType.AFTER_LAYER currently unsupported in PT">/home/liubov/nncf/tests/torch/test_nncf_network.py:300: Insertion type TargetType.AFTER_LAYER currently unsupported in PT</skipped></testcase><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[PRE_LAYER_OPERATION-same]" time="0.005"><skipped type="pytest.skip" message="Insertion type TargetType.PRE_LAYER_OPERATION currently unsupported in PT">/home/liubov/nncf/tests/torch/test_nncf_network.py:300: Insertion type TargetType.PRE_LAYER_OPERATION currently unsupported in PT</skipped></testcase><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[POST_LAYER_OPERATION-same]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[OPERATION_WITH_WEIGHTS-same]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[OPERATOR_PRE_HOOK-same]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[OPERATOR_POST_HOOK-same]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[LAYER-different]" time="0.005"><skipped type="pytest.skip" message="Insertion type TargetType.LAYER currently unsupported in PT">/home/liubov/nncf/tests/torch/test_nncf_network.py:300: Insertion type TargetType.LAYER currently unsupported in PT</skipped></testcase><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[BEFORE_LAYER-different]" time="0.005"><skipped type="pytest.skip" message="Insertion type TargetType.BEFORE_LAYER currently unsupported in PT">/home/liubov/nncf/tests/torch/test_nncf_network.py:300: Insertion type TargetType.BEFORE_LAYER currently unsupported in PT</skipped></testcase><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[AFTER_LAYER-different]" time="0.005"><skipped type="pytest.skip" message="Insertion type TargetType.AFTER_LAYER currently unsupported in PT">/home/liubov/nncf/tests/torch/test_nncf_network.py:300: Insertion type TargetType.AFTER_LAYER currently unsupported in PT</skipped></testcase><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[PRE_LAYER_OPERATION-different]" time="0.005"><skipped type="pytest.skip" message="Insertion type TargetType.PRE_LAYER_OPERATION currently unsupported in PT">/home/liubov/nncf/tests/torch/test_nncf_network.py:300: Insertion type TargetType.PRE_LAYER_OPERATION currently unsupported in PT</skipped></testcase><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[POST_LAYER_OPERATION-different]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[OPERATION_WITH_WEIGHTS-different]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[OPERATOR_PRE_HOOK-different]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionCommands" name="test_priority[OPERATOR_POST_HOOK-different]" time="0.005" /><testcase classname="tests.torch.test_nncf_network.TestInsertionPointGraph" name="test_insertion_point_setup" time="0.002" /><testcase classname="tests.torch.test_nncf_network.TestInsertionPointGraph" name="test_insertion_point_data_in_ip_nodes" time="0.001" /><testcase classname="tests.torch.test_nncf_network.TestInsertionPointGraph" name="test_operator_metatype_marking" time="0.021" /><testcase classname="tests.torch.test_nncf_network.TestInsertionPointGraph" name="test_get_ip_graph_with_merged_operations[basic_pattern]" time="0.171" /><testcase classname="tests.torch.test_nncf_network.TestInsertionPointGraph" name="test_get_ip_graph_with_merged_operations[no_pattern]" time="0.044" /><testcase classname="tests.torch.test_nncf_network.TestInsertionPointGraph" name="test_get_ip_graph_with_merged_operations[broken_output_edges_pattern]" time="0.039" /><testcase classname="tests.torch.test_nncf_network" name="test_disable_shape_matching" time="0.007" /><testcase classname="tests.torch.test_nncf_network" name="test_check_correct_modules_replacement" time="0.006" /><testcase classname="tests.torch.test_nncf_network" name="test_custom_module_registering" time="0.005"><failure message="AssertionError: assert ModuleOfUser in dict_values([&lt;class 'examples.torch.object_detection.layers.modules.l2norm.L2Norm'&gt;, &lt;class 'tests.torch.test_models.synthetic.ManyNonEvalModules.CustomWeightModule'&gt;, &lt;class 'tests.torch.test_nncf_network.ModuleOfUser'&gt;])&#10; +  where dict_values([&lt;class 'examples.torch.object_detection.layers.modules.l2norm.L2Norm'&gt;, &lt;class 'tests.torch.test_models.synthetic.ManyNonEvalModules.CustomWeightModule'&gt;, &lt;class 'tests.torch.test_nncf_network.ModuleOfUser'&gt;]) = &lt;built-in method values of dict object at 0x7fefb5215c00&gt;()&#10; +    where &lt;built-in method values of dict object at 0x7fefb5215c00&gt; = {'CustomWeightModule': &lt;class 'tests.torch.test_models.synthetic.ManyNonEvalModules.CustomWeightModule'&gt;, 'L2Norm': &lt;c....object_detection.layers.modules.l2norm.L2Norm'&gt;, 'ModuleOfUser': &lt;class 'tests.torch.test_nncf_network.ModuleOfUser'&gt;}.values&#10; +      where {'CustomWeightModule': &lt;class 'tests.torch.test_models.synthetic.ManyNonEvalModules.CustomWeightModule'&gt;, 'L2Norm': &lt;c....object_detection.layers.modules.l2norm.L2Norm'&gt;, 'ModuleOfUser': &lt;class 'tests.torch.test_nncf_network.ModuleOfUser'&gt;} = &lt;nncf.common.utils.registry.Registry object at 0x7fefb520dd60&gt;.registry_dict">def test_custom_module_registering():
        model = TwoConvTestModelWithUserModule()
        nncf_model = NNCFNetwork(model, input_infos=[ModelInputInfo([1, 1, 4, 4])])  # type: NNCFNetwork
    
        from nncf.torch.layers import UNWRAPPED_USER_MODULES
&gt;       assert ModuleOfUser in UNWRAPPED_USER_MODULES.registry_dict.values()
E       AssertionError: assert ModuleOfUser in dict_values([&lt;class 'examples.torch.object_detection.layers.modules.l2norm.L2Norm'&gt;, &lt;class 'tests.torch.test_models.synthetic.ManyNonEvalModules.CustomWeightModule'&gt;, &lt;class 'tests.torch.test_nncf_network.ModuleOfUser'&gt;])
E        +  where dict_values([&lt;class 'examples.torch.object_detection.layers.modules.l2norm.L2Norm'&gt;, &lt;class 'tests.torch.test_models.synthetic.ManyNonEvalModules.CustomWeightModule'&gt;, &lt;class 'tests.torch.test_nncf_network.ModuleOfUser'&gt;]) = &lt;built-in method values of dict object at 0x7fefb5215c00&gt;()
E        +    where &lt;built-in method values of dict object at 0x7fefb5215c00&gt; = {'CustomWeightModule': &lt;class 'tests.torch.test_models.synthetic.ManyNonEvalModules.CustomWeightModule'&gt;, 'L2Norm': &lt;c....object_detection.layers.modules.l2norm.L2Norm'&gt;, 'ModuleOfUser': &lt;class 'tests.torch.test_nncf_network.ModuleOfUser'&gt;}.values
E        +      where {'CustomWeightModule': &lt;class 'tests.torch.test_models.synthetic.ManyNonEvalModules.CustomWeightModule'&gt;, 'L2Norm': &lt;c....object_detection.layers.modules.l2norm.L2Norm'&gt;, 'ModuleOfUser': &lt;class 'tests.torch.test_nncf_network.ModuleOfUser'&gt;} = &lt;nncf.common.utils.registry.Registry object at 0x7fefb520dd60&gt;.registry_dict

test_nncf_network.py:135: AssertionError</failure></testcase><testcase classname="tests.torch.test_nncf_network" name="test_find_node_in_nx_graph_by_scope" time="0.007" /><testcase classname="tests.torch.test_nncf_network" name="test_can_collect_scopes_of_train_only_modules" time="0.002" /><testcase classname="tests.torch.test_nncf_network" name="test_get_clean_shallow_copy" time="0.043" /><testcase classname="tests.torch.test_nncf_network" name="test_temporary_clean_view" time="0.051" /><testcase classname="tests.torch.test_nncf_network" name="test_multiple_forward" time="0.033" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk[objwalk_objects0]" time="0.000" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk[objwalk_objects1]" time="0.000" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk[objwalk_objects2]" time="0.001" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk[objwalk_objects3]" time="0.000" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk[objwalk_objects4]" time="0.000" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk[objwalk_objects5]" time="0.000" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk[objwalk_objects6]" time="0.000" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk[objwalk_objects7]" time="0.000" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk[objwalk_objects8]" time="0.001" /><testcase classname="tests.torch.test_nncf_utils" name="test_objwalk_retains_named_tuple" time="0.000" /><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_install_trans_" time="0.000"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sanity_third_party.py:41: Skipped</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_xnli_train" time="0.000"><skipped type="pytest.skip" message="test_xnli_train depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_xnli_train depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_xnli_eval" time="0.000"><skipped type="pytest.skip" message="test_xnli_eval depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_xnli_eval depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_squad_train" time="0.000"><skipped type="pytest.skip" message="test_squad_train depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_squad_train depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_squad_eval" time="0.000"><skipped type="pytest.skip" message="test_squad_eval depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_squad_eval depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_glue_train" time="0.000"><skipped type="pytest.skip" message="test_glue_train depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_glue_train depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_glue_eval" time="0.000"><skipped type="pytest.skip" message="test_glue_eval depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_glue_eval depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_glue_distilbert_train" time="0.000"><skipped type="pytest.skip" message="test_glue_distilbert_train depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_glue_distilbert_train depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_glue_distilbert_eval" time="0.000"><skipped type="pytest.skip" message="test_glue_distilbert_eval depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_glue_distilbert_eval depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_lm_train" time="0.000"><skipped type="pytest.skip" message="test_lm_train depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_lm_train depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_lm_eval" time="0.000"><skipped type="pytest.skip" message="test_lm_eval depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_lm_eval depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestTransformers" name="test_convert_to_onnx" time="0.000"><skipped type="pytest.skip" message="test_convert_to_onnx depends on install_trans">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_convert_to_onnx depends on install_trans</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestMmdetection" name="test_install_mmdet" time="0.000"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sanity_third_party.py:41: Skipped</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestMmdetection" name="test_ssd300_train" time="0.000"><skipped type="pytest.skip" message="test_ssd300_train depends on install_mmdet">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_ssd300_train depends on install_mmdet</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestMmdetection" name="test_ssd300_eval" time="0.000"><skipped type="pytest.skip" message="test_ssd300_eval depends on install_mmdet">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_ssd300_eval depends on install_mmdet</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestMmdetection" name="test_ssd300_export2onnx" time="0.000"><skipped type="pytest.skip" message="test_ssd300_export2onnx depends on install_mmdet">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_ssd300_export2onnx depends on install_mmdet</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestMmdetection" name="test_retinanet_train" time="0.000"><skipped type="pytest.skip" message="test_retinanet_train depends on install_mmdet">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_retinanet_train depends on install_mmdet</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestMmdetection" name="test_retinanet_eval" time="0.000"><skipped type="pytest.skip" message="test_retinanet_eval depends on install_mmdet">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_retinanet_eval depends on install_mmdet</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestMmdetection" name="test_retinanet_export2onnx" time="0.000"><skipped type="pytest.skip" message="test_retinanet_export2onnx depends on install_mmdet">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_retinanet_export2onnx depends on install_mmdet</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestMmdetection" name="test_maskrcnn_train" time="0.000"><skipped type="pytest.skip" message="test_maskrcnn_train depends on install_mmdet">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_maskrcnn_train depends on install_mmdet</skipped></testcase><testcase classname="tests.torch.test_sanity_third_party.TestMmdetection" name="test_maskrcnn_eval" time="0.000"><skipped type="pytest.skip" message="test_maskrcnn_eval depends on install_mmdet">/home/liubov/miniconda3/envs/pytorch/lib/python3.8/site-packages/pytest_dependency.py:103: test_maskrcnn_eval depends on install_mmdet</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet50_imagenet]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet50_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet50_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet50_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet50_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet50_imagenet_rb_sparsity50_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet50_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[inception_v3_imagenet]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[inception_v3_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[inception_v3_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[mobilenet_v2_imagenet]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[mobilenet_v2_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[mobilenet_v2_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[mobilenet_v2_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[mobilenet_v2_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[squeezenet1_1_imagenet]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[squeezenet1_1_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[squeezenet1_1_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[squeezenet1_1_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet18_imagenet]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet18_imagenet_binarization_xnor]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet18_imagenet_binarization_dorefa]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet18_imagenet_filter_pruning_magnitude]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet18_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet34_imagenet]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[resnet34_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[googlenet_imagenet]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[googlenet_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[ssd300_mobilenet_voc]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[ssd300_mobilenet_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[ssd300_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[ssd300_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[ssd300_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[ssd300_vgg_voc_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[ssd512_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[ssd512_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[ssd512_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[unet_camvid]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[unet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[unet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[icnet_camvid]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[icnet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[icnet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[unet_mapillary]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[unet_mapillary_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[unet_mapillary_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_eval[unet_mapillary_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:351: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet50_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet50_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet50_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet50_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet50_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet50_imagenet_rb_sparsity50_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet50_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-inception_v3_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-inception_v3_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-inception_v3_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-mobilenet_v2_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-mobilenet_v2_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-mobilenet_v2_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-mobilenet_v2_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-mobilenet_v2_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-squeezenet1_1_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-squeezenet1_1_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-squeezenet1_1_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-squeezenet1_1_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet18_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet18_imagenet_binarization_xnor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet18_imagenet_binarization_dorefa]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet18_imagenet_filter_pruning_magnitude]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet18_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet34_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-resnet34_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-googlenet_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-googlenet_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-ssd300_mobilenet_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-ssd300_mobilenet_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-ssd300_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-ssd300_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-ssd300_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-ssd300_vgg_voc_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-ssd512_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-ssd512_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-ssd512_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-unet_camvid]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-unet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-unet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-icnet_camvid]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-icnet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-icnet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-unet_mapillary]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-unet_mapillary_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-unet_mapillary_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[fq-unet_mapillary_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet50_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet50_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet50_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet50_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet50_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet50_imagenet_rb_sparsity50_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet50_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-inception_v3_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-inception_v3_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-inception_v3_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-mobilenet_v2_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-mobilenet_v2_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-mobilenet_v2_imagenet_int8_per_tensor]" time="0.002"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-mobilenet_v2_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-mobilenet_v2_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-squeezenet1_1_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-squeezenet1_1_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-squeezenet1_1_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-squeezenet1_1_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet18_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet18_imagenet_binarization_xnor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet18_imagenet_binarization_dorefa]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet18_imagenet_filter_pruning_magnitude]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet18_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet34_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-resnet34_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-googlenet_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-googlenet_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-ssd300_mobilenet_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-ssd300_mobilenet_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-ssd300_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-ssd300_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-ssd300_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-ssd300_vgg_voc_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-ssd512_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-ssd512_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-ssd512_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-unet_camvid]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-unet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-unet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-icnet_camvid]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-icnet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-icnet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-unet_mapillary]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-unet_mapillary_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-unet_mapillary_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_convert_to_onnx[q_dq-unet_mapillary_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:427: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet50_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet50_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet50_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet50_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet50_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet50_imagenet_rb_sparsity50_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet50_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-inception_v3_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-inception_v3_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-inception_v3_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-mobilenet_v2_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-mobilenet_v2_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-mobilenet_v2_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-mobilenet_v2_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-mobilenet_v2_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-squeezenet1_1_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-squeezenet1_1_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-squeezenet1_1_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-squeezenet1_1_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet18_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet18_imagenet_binarization_xnor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet18_imagenet_binarization_dorefa]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet18_imagenet_filter_pruning_magnitude]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet18_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet34_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-resnet34_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-googlenet_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-googlenet_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-ssd300_mobilenet_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-ssd300_mobilenet_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-ssd300_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-ssd300_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-ssd300_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-ssd300_vgg_voc_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-ssd512_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-ssd512_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-ssd512_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-unet_camvid]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-unet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-unet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-icnet_camvid]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-icnet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-icnet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-unet_mapillary]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-unet_mapillary_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-unet_mapillary_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[fq-unet_mapillary_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet50_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet50_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet50_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet50_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet50_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet50_imagenet_rb_sparsity50_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet50_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-inception_v3_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-inception_v3_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-inception_v3_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-mobilenet_v2_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-mobilenet_v2_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-mobilenet_v2_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-mobilenet_v2_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-mobilenet_v2_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-squeezenet1_1_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-squeezenet1_1_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-squeezenet1_1_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-squeezenet1_1_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet18_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet18_imagenet_binarization_xnor]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet18_imagenet_binarization_dorefa]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet18_imagenet_filter_pruning_magnitude]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet18_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet34_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-resnet34_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-googlenet_imagenet]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-googlenet_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-ssd300_mobilenet_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-ssd300_mobilenet_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-ssd300_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-ssd300_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-ssd300_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-ssd300_vgg_voc_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-ssd512_vgg_voc]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-ssd512_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-ssd512_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-unet_camvid]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-unet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-unet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-icnet_camvid]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-icnet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-icnet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-unet_mapillary]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-unet_mapillary_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-unet_mapillary_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_openvino_eval[q_dq-unet_mapillary_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Skipped">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:469: Skipped</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet50_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet50_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet50_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet50_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet50_imagenet_rb_sparsity50_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet50_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[inception_v3_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[inception_v3_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[mobilenet_v2_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[mobilenet_v2_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[mobilenet_v2_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[mobilenet_v2_imagenet_rb_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[squeezenet1_1_imagenet_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[squeezenet1_1_imagenet_int8_per_tensor]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[squeezenet1_1_imagenet_int4_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet18_imagenet_binarization_xnor]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet18_imagenet_binarization_dorefa]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet18_imagenet_filter_pruning_magnitude]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet18_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[resnet34_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[googlenet_imagenet_filter_pruning_geomean]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[ssd300_mobilenet_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[ssd300_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[ssd300_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[ssd300_vgg_voc_pruning_geometric_median]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[ssd512_vgg_voc_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[ssd512_vgg_voc_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[unet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[unet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[icnet_camvid_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[icnet_camvid_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[unet_mapillary_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[unet_mapillary_magnitude_sparsity_int8]" time="0.001"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_sota_checkpoints.TestSotaCheckpoints" name="test_train[unet_mapillary_pruning_geometric_median]" time="0.015"><skipped type="pytest.skip" message="Path to datasets is not set">/home/liubov/nncf/tests/torch/test_sota_checkpoints.py:511: Path to datasets is not set</skipped></testcase><testcase classname="tests.torch.test_utils" name="test_training_mode_switcher[model0]" time="0.001" /><testcase classname="tests.torch.test_utils" name="test_training_mode_switcher[model1]" time="0.001" /><testcase classname="tests.torch.test_utils" name="test_training_mode_switcher[model2]" time="0.001" /><testcase classname="tests.torch.test_utils" name="test_training_mode_switcher[model3]" time="0.001" /><testcase classname="tests.torch.test_utils" name="test_training_mode_switcher[model4]" time="0.001" /><testcase classname="tests.torch.test_utils" name="test_bn_training_state_switcher[model0]" time="0.001" /><testcase classname="tests.torch.test_utils" name="test_bn_training_state_switcher[model1]" time="0.001" /><testcase classname="tests.torch.test_utils" name="test_bn_training_state_switcher[model2]" time="0.001" /><testcase classname="tests.torch.test_utils" name="test_bn_training_state_switcher[model3]" time="0.001" /><testcase classname="tests.torch.test_utils" name="test_bn_training_state_switcher[model4]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_valid_input[num_state_1-num_action_1]" time="0.024" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_valid_input[num_state_1-num_action_5]" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_valid_input[num_state_3-num_action_1]" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_valid_input[num_state_3-num_action_5]" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_2.5-num_action_2.5]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_2.5-num_action_0]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_2.5-num_action_-1]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_2.5-num_action_None]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_2.5-num_action_string]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_0-num_action_2.5]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_0-num_action_0]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_0-num_action_-1]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_0-num_action_None]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_0-num_action_string]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_-1-num_action_2.5]" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_-1-num_action_0]" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_-1-num_action_-1]" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_-1-num_action_None]" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_-1-num_action_string]" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_None-num_action_2.5]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_None-num_action_0]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_None-num_action_-1]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_None-num_action_None]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_None-num_action_string]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_string-num_action_2.5]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_string-num_action_0]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_string-num_action_-1]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_string-num_action_None]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_create_ddpg_with_invalid_input[num_state_string-num_action_string]" time="0.001" /><testcase classname="tests.torch.automl.test_ddpg" name="test_random_action" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_select_action[actor_with_noise_True-episode_0]" time="0.003" /><testcase classname="tests.torch.automl.test_ddpg" name="test_select_action[actor_with_noise_True-episode_10]" time="0.003" /><testcase classname="tests.torch.automl.test_ddpg" name="test_select_action[actor_with_noise_True-episode_100]" time="0.003" /><testcase classname="tests.torch.automl.test_ddpg" name="test_select_action[actor_with_noise_True-episode_1000]" time="0.003" /><testcase classname="tests.torch.automl.test_ddpg" name="test_select_action[actor_with_noise_False-episode_0]" time="0.002" /><testcase classname="tests.torch.automl.test_ddpg" name="test_select_action[actor_with_noise_False-episode_10]" time="0.002" /><testcase classname="tests.torch.automl.test_ddpg" name="test_select_action[actor_with_noise_False-episode_100]" time="0.002" /><testcase classname="tests.torch.automl.test_ddpg" name="test_select_action[actor_with_noise_False-episode_1000]" time="0.002" /><testcase classname="tests.torch.automl.test_ddpg" name="test_update_policy[batch_size_4-discount_factor_1.0-moving_avg_False]" time="0.008" /><testcase classname="tests.torch.automl.test_ddpg" name="test_update_policy[batch_size_4-discount_factor_0.9-moving_avg_True]" time="0.006" /><testcase classname="tests.torch.automl.test_ddpg" name="test_update_policy[batch_size_8-discount_factor_1.0-moving_avg_True]" time="0.006" /><testcase classname="tests.torch.automl.test_ddpg" name="test_update_policy[batch_size_8-discount_factor_0.8-moving_avg_False]" time="0.006" /><testcase classname="tests.torch.automl.test_ddpg" name="test_soft_update" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_hard_update" time="0.004" /><testcase classname="tests.torch.automl.test_ddpg" name="test_observe" time="0.004" /><testcase classname="tests.torch.automl.test_memory" name="test_can_create_memory" time="0.000" /><testcase classname="tests.torch.automl.test_memory" name="test_get_recent_state_with_episode_boundaries" time="0.001" /><testcase classname="tests.torch.automl.test_memory" name="test_training_flag" time="0.001" /><testcase classname="tests.torch.automl.test_memory" name="test_get_recent_state_without_episode_boundaries" time="0.001" /><testcase classname="tests.torch.automl.test_memory" name="test_sampling" time="0.001" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_can_create_quant_env" time="0.033" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_step[bitwidth_cfg_[2, 2]]" time="0.042" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_step[bitwidth_cfg_[2, 4]]" time="0.041" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_step[bitwidth_cfg_[2, 8]]" time="0.041" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_step[bitwidth_cfg_[4, 4]]" time="0.040" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_step[bitwidth_cfg_[4, 8]]" time="0.042" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_step[bitwidth_cfg_[1, 6]]" time="0.041" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_step[bitwidth_cfg_[16, 1]]" time="0.040" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_overflow_step" time="0.040" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_74.3-compressed_score_0.12-size_ratio_0.12]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_74.3-compressed_score_0.12-size_ratio_2]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_74.3-compressed_score_0.12-size_ratio_False]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_74.3-compressed_score_-7.23-size_ratio_0.12]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_74.3-compressed_score_-7.23-size_ratio_2]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_74.3-compressed_score_-7.23-size_ratio_False]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_74.3-compressed_score_dummy-size_ratio_0.12]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_74.3-compressed_score_dummy-size_ratio_2]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_74.3-compressed_score_dummy-size_ratio_False]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_-0.11-compressed_score_0.12-size_ratio_0.12]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_-0.11-compressed_score_0.12-size_ratio_2]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_-0.11-compressed_score_0.12-size_ratio_False]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_-0.11-compressed_score_-7.23-size_ratio_0.12]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_-0.11-compressed_score_-7.23-size_ratio_2]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_-0.11-compressed_score_-7.23-size_ratio_False]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_-0.11-compressed_score_dummy-size_ratio_0.12]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_-0.11-compressed_score_dummy-size_ratio_2]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_-0.11-compressed_score_dummy-size_ratio_False]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_None-compressed_score_0.12-size_ratio_0.12]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_None-compressed_score_0.12-size_ratio_2]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_None-compressed_score_0.12-size_ratio_False]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_None-compressed_score_-7.23-size_ratio_0.12]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_None-compressed_score_-7.23-size_ratio_2]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_None-compressed_score_-7.23-size_ratio_False]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_None-compressed_score_dummy-size_ratio_0.12]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_None-compressed_score_dummy-size_ratio_2]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_reward[pretrained_score_None-compressed_score_dummy-size_ratio_False]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_evaluate_strategy[bitwidth_strategy_[2]-skip_constraint_True]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_evaluate_strategy[bitwidth_strategy_[2]-skip_constraint_False]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_evaluate_strategy[bitwidth_strategy_[8, 8]-skip_constraint_True]" time="0.036" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_evaluate_strategy[bitwidth_strategy_[8, 8]-skip_constraint_False]" time="0.038" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_evaluate_strategy[bitwidth_strategy_[4, 8, 2]-skip_constraint_True]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_evaluate_strategy[bitwidth_strategy_[4, 8, 2]-skip_constraint_False]" time="0.031" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_one_wq[bitwidth_strategy_[8, 8]]" time="0.042" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_one_wq[bitwidth_strategy_[8, 4]]" time="0.043" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_one_wq[bitwidth_strategy_[8, 2]]" time="0.042" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_one_wq[bitwidth_strategy_[4, 8]]" time="0.042" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_one_wq[bitwidth_strategy_[4, 4]]" time="0.042" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_one_wq[bitwidth_strategy_[4, 2]]" time="0.042" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[4, 2, 2]]" time="0.054" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[4, 2, 4]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[4, 2, 8]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[4, 4, 2]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[4, 4, 4]]" time="0.054" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[4, 4, 8]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[4, 8, 2]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[4, 8, 4]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[4, 8, 8]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[8, 2, 2]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[8, 2, 4]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[8, 2, 8]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[8, 4, 2]]" time="0.054" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[8, 4, 4]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[8, 4, 8]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[8, 8, 2]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[8, 8, 4]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_one_aq_two_wq[bitwidth_strategy_[8, 8, 8]]" time="0.053" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[4, 4, 2]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[4, 4, 4]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[4, 4, 8]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[4, 8, 2]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[4, 8, 4]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[4, 8, 8]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[8, 4, 2]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[8, 4, 4]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[8, 4, 8]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[8, 8, 2]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[8, 8, 4]]" time="0.040" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_align_bw_action_two_aq_one_wq[bitwidth_strategy_[8, 8, 8]]" time="0.039" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_select_config_for_actions[vpu_unmappable_strategy_[2, 8]]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_select_config_for_actions[vpu_unmappable_strategy_[2, 4]]" time="0.030" /><testcase classname="tests.torch.automl.test_quantization_env" name="test_select_config_for_actions[vpu_unmappable_strategy_[2, 2]]" time="0.030" /><testcase classname="tests.torch.automl.test_ring_buffer" name="test_create_ring_buffer" time="0.000" /><testcase classname="tests.torch.automl.test_ring_buffer" name="test_append" time="0.000" /><testcase classname="tests.torch.automl.test_ring_buffer" name="test_delitem" time="0.000" /><testcase classname="tests.torch.automl.test_ring_buffer" name="test_delslice" time="0.000" /><testcase classname="tests.torch.automl.test_ring_buffer" name="test_del_append" time="0.000" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cpu-[1-96-112-112]]" time="0.037" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cpu-[1-192-28-28]]" time="0.005" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cpu-[1-576-14-14]]" time="0.004" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cpu-[32-96-112-112]]" time="1.329" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cpu-[32-192-28-28]]" time="0.150" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cpu-[32-576-14-14]]" time="0.110" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cuda-[1-96-112-112]]" time="0.036" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cuda-[1-192-28-28]]" time="0.005" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cuda-[1-576-14-14]]" time="0.004" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cuda-[32-96-112-112]]" time="1.258" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cuda-[32-192-28-28]]" time="0.139" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[xnor-cuda-[32-576-14-14]]" time="0.105" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cpu-[1-96-112-112]]" time="0.034" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cpu-[1-192-28-28]]" time="0.005" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cpu-[1-576-14-14]]" time="0.004" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cpu-[32-96-112-112]]" time="1.331" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cpu-[32-192-28-28]]" time="0.149" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cpu-[32-576-14-14]]" time="0.109" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cuda-[1-96-112-112]]" time="0.036" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cuda-[1-192-28-28]]" time="0.005" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cuda-[1-576-14-14]]" time="0.004" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cuda-[32-96-112-112]]" time="1.255" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cuda-[32-192-28-28]]" time="0.138" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized.TestWeightBinarization" name="test_binarize_weights_forward[dorefa-cuda-[32-576-14-14]]" time="0.105" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cpu-[1-96-112-112]]" time="0.032" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cpu-[1-192-28-28]]" time="0.005" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cpu-[1-576-14-14]]" time="0.004" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cpu-[32-96-112-112]]" time="1.151" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cpu-[32-192-28-28]]" time="0.128" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cpu-[32-576-14-14]]" time="0.098" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cuda-[1-96-112-112]]" time="0.034" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cuda-[1-192-28-28]]" time="0.005" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cuda-[1-576-14-14]]" time="0.004" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cuda-[32-96-112-112]]" time="1.143" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cuda-[32-192-28-28]]" time="0.126" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_forward[cuda-[32-576-14-14]]" time="0.095" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cpu-[1-96-112-112]]" time="0.059" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cpu-[1-192-28-28]]" time="0.008" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cpu-[1-576-14-14]]" time="0.006" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cpu-[32-96-112-112]]" time="2.511" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cpu-[32-192-28-28]]" time="0.315" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cpu-[32-576-14-14]]" time="0.205" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cuda-[1-96-112-112]]" time="0.066" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cuda-[1-192-28-28]]" time="0.010" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cuda-[1-576-14-14]]" time="0.014" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cuda-[32-96-112-112]]" time="2.226" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cuda-[32-192-28-28]]" time="0.262" /><testcase classname="tests.torch.binarization.test_functions.TestParametrized" name="test_binarize_activations_backward[cuda-[32-576-14-14]]" time="0.195" /><testcase classname="tests.torch.composite.test_composite_scheduler" name="test_can_restore_from_state" time="0.001" /><testcase classname="tests.torch.composite.test_sparsity_quantization" name="test_can_quantize_inputs_for_sparsity_plus_quantization" time="0.026" /><testcase classname="tests.torch.modules.test_rnn.TestLSTMCell" name="test_forward_lstm_cell[[512-768-128-50]]" time="0.278" /><testcase classname="tests.torch.modules.test_rnn.TestLSTMCell" name="test_forward_lstm_cell[[3-3-3-3]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTMCell" name="test_forward_lstm_cell[[1-1-1-1]]" time="0.001" /><testcase classname="tests.torch.modules.test_rnn.TestLSTMCell" name="test_backward_lstm_cell[[512-768-128-50]]" time="1.051" /><testcase classname="tests.torch.modules.test_rnn.TestLSTMCell" name="test_backward_lstm_cell[[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTMCell" name="test_backward_lstm_cell[[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.095" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.053" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.086" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.052" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.168" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.082" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.158" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.080" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.053" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.086" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.052" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.162" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.082" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.157" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.079" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.089" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.054" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.087" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.053" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.164" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.083" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.158" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.080" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.090" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.055" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.054" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.164" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.084" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.160" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.081" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.086" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.055" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.083" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.054" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.162" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.081" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.148" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.079" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.086" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.055" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.084" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.054" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.153" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.081" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.148" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.079" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.163" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.154" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.085" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.308" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.146" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.293" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.139" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.160" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.153" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.084" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.308" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.146" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.293" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.139" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.161" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.089" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.154" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.085" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.308" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.148" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.293" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.139" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.163" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.090" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.155" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.086" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.309" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.147" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.294" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.140" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.204" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.110" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.190" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.110" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.398" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.023" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.180" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.457" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.024" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.179" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.201" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.012" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.136" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.191" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.108" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.395" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.023" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.180" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.453" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.013" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.184" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.091" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.055" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.053" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.167" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.084" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.308" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.082" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.090" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.055" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.053" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.167" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.084" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.162" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.082" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.092" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.056" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.089" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.054" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.168" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.085" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.163" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.083" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.093" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.057" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.090" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.055" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.169" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.103" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.166" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.084" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.056" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.086" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.055" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.158" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.084" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.152" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.081" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.056" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.086" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.055" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.157" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.084" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.152" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.081" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.164" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.090" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.157" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.087" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.312" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.148" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.298" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.141" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.164" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.089" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.157" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.086" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.310" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.148" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.298" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.142" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.185" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.090" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.157" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.087" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.309" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.149" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.299" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.142" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.165" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.091" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.158" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.312" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.149" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.300" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.143" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.202" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.116" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.194" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.111" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.400" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.024" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.183" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.457" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.024" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.182" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.204" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.114" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.194" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.109" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.397" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.023" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.181" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.459" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.023" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.176" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_forward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.121" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.068" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.110" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.065" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.224" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.014" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.113" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.211" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.107" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.116" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.068" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.110" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.064" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.223" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.014" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.113" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.210" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.107" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.117" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.069" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.111" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.066" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.224" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.014" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.114" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.212" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.013" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.108" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.119" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.089" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.142" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.085" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.225" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.014" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.115" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.213" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.135" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.110" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.068" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.104" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.065" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.221" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.014" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.132" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.204" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.133" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.110" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.067" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.104" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.064" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.212" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.014" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.137" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.203" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.102" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.380" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.203" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.370" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.194" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.929" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.384" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.908" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.372" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.379" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.201" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.369" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.194" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.930" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.384" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.907" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.371" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.385" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.201" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.367" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.193" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.929" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.384" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.909" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.369" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.381" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.201" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.367" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.219" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.930" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.013" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.383" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.864" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.376" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.334" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.175" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.313" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.167" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.836" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.021" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.339" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.936" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.021" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.334" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.325" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.174" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.311" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.165" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.865" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.019" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.350" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.902" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.021" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.333" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-no_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.136" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.081" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.115" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.066" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.225" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.016" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.012" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.129" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.216" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.013" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.130" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.121" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.147" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.066" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.226" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.016" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.012" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.134" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.214" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.013" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.132" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_sorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.123" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.070" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.112" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.086" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.270" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.015" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.012" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.148" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.220" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.013" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.141" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.123" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.071" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.113" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.088" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.234" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.015" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.117" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.254" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.012" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.107" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-packed_unsorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.149" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.069" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.144" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.066" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.228" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.015" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.136" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.210" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.104" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.108" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.092" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.117" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.066" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.215" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.015" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.011" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.123" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.206" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.012" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.127" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cuda-not_packed-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.392" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.204" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.377" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.196" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.906" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.384" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.915" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.372" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.392" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.205" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.377" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.195" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.907" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.383" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.918" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.373" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_sorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.392" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.203" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.379" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.218" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.947" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.385" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.912" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.375" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.391" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.204" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.380" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.198" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.946" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.013" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.008" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.401" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.916" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.009" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.375" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-packed_unsorted-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[512-324-128-50]]" time="0.328" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[512-324-128-50]]" time="0.175" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.313" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.168" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-bi-[512-324-128-50]]" time="0.873" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-bi-[3-3-3-3]]" time="0.022" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-uni-[512-324-128-50]]" time="0.349" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.887" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.023" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.330" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.007" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-batch_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[512-324-128-50]]" time="0.353" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-bi-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[512-324-128-50]]" time="0.173" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[512-324-128-50]]" time="0.312" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-bi-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[512-324-128-50]]" time="0.166" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[3-3-3-3]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-single_layer-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-bi-[512-324-128-50]]" time="0.870" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-bi-[3-3-3-3]]" time="0.021" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-bi-[1-1-1-1]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-uni-[512-324-128-50]]" time="0.350" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-uni-[3-3-3-3]]" time="0.006" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-bias-uni-[1-1-1-1]]" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[512-324-128-50]]" time="0.903" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[3-3-3-3]]" time="0.021" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-bi-[1-1-1-1]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[512-324-128-50]]" time="0.328" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[3-3-3-3]]" time="0.005" /><testcase classname="tests.torch.modules.test_rnn.TestLSTM" name="test_backward_lstm[no_dropout-with_initial-cpu-not_packed-seq_first-stacked-no_bias-uni-[1-1-1-1]]" time="0.003" /><testcase classname="tests.torch.modules.test_rnn.TestNumberOfNodes" name="test_number_of_calling_fq_for_lstm" time="0.492" /><testcase classname="tests.torch.modules.test_rnn.TestNumberOfNodes" name="test_number_of_calling_fq_for_gnmt" time="11.390" /><testcase classname="tests.torch.modules.test_rnn.TestNumberOfNodes" name="test_number_of_nodes_for_module_in_loop" time="0.002" /><testcase classname="tests.torch.modules.test_rnn.TestNumberOfNodes" name="test_number_of_nodes_for_module_in_loop__not_input_node" time="0.004" /><testcase classname="tests.torch.modules.test_rnn.TestNumberOfNodes" name="test_number_of_nodes_for_module_with_nested_loops" time="0.010" /><testcase classname="tests.torch.modules.test_rnn.TestNumberOfNodes" name="test_number_of_nodes_for_repeated_module" time="0.002" /><testcase classname="tests.torch.modules.test_rnn" name="test_export_lstm_cell" time="0.131" /><testcase classname="tests.torch.modules.test_rnn" name="test_export_stacked_bi_lstm" time="0.665" /><testcase classname="tests.torch.pruning.test_common" name="test_can_choose_scheduler[baseline-BaselinePruningScheduler-filter_pruning]" time="0.015" /><testcase classname="tests.torch.pruning.test_common" name="test_can_choose_scheduler[exponential-ExponentialPruningScheduler-filter_pruning]" time="0.015" /><testcase classname="tests.torch.pruning.test_common" name="test_can_choose_scheduler[exponential_with_bias-ExponentialWithBiasPruningScheduler-filter_pruning]" time="0.015" /><testcase classname="tests.torch.pruning.test_common" name="test_check_default_scheduler_params[filter_pruning-BaselinePruningScheduler-ref_scheduler_params0]" time="0.015" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_groups[test_input_info_struct_0]" time="0.023" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_groups[test_input_info_struct_1]" time="0.024" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_groups[test_input_info_struct_2]" time="0.025" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_groups[test_input_info_struct_3]" time="0.024" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_groups[test_input_info_struct_4]" time="0.024" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_groups[test_input_info_struct_5]" time="0.027" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_groups[test_input_info_struct_6]" time="0.030" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_pruning_node_selector[test_input_info_struct_0]" time="0.009" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_pruning_node_selector[test_input_info_struct_1]" time="0.009" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_pruning_node_selector[test_input_info_struct_2]" time="0.009" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_pruning_node_selector[test_input_info_struct_3]" time="0.009" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_pruning_node_selector[test_input_info_struct_4]" time="0.009" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_pruning_node_selector[test_input_info_struct_5]" time="0.011" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_pruning_node_selector[test_input_info_struct_6]" time="0.011" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_group_special_nodes[test_special_ops_struct0]" time="0.015" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_group_special_nodes[test_special_ops_struct1]" time="0.017" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_group_special_nodes[test_special_ops_struct2]" time="0.017" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_model_analyzer[test_struct0]" time="0.017" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_is_module_prunable[test_prunable_struct0]" time="0.014" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_is_module_prunable[test_prunable_struct1]" time="0.014" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_is_module_prunable[test_prunable_struct2]" time="0.014" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_is_module_prunable[test_prunable_struct3]" time="0.015" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_is_module_prunable[test_prunable_struct4]" time="0.015" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_is_module_prunable[test_prunable_struct5]" time="0.018" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_is_module_prunable[test_prunable_struct6]" time="0.015" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_nodes_cluster" time="0.000" /><testcase classname="tests.torch.pruning.test_model_pruning_analysis" name="test_clusterization" time="0.000" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_simple_model" time="0.076" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_concat_model[False-True-ref_shapes0]" time="0.068" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_concat_model[True-True-ref_shapes1]" time="0.068" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_concat_model[False-False-ref_shapes2]" time="0.066" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_concat_model[True-False-ref_shapes3]" time="0.067" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_eltwise_model[False-True-ref_shapes0]" time="0.068" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_eltwise_model[True-True-ref_shapes1]" time="0.069" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_eltwise_model[False-False-ref_shapes2]" time="0.068" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_eltwise_model[True-False-ref_shapes3]" time="0.068" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_diffconvs_model[False-True-ref_shapes0]" time="0.061" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_diffconvs_model[True-True-ref_shapes1]" time="0.064" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_diffconvs_model[False-False-ref_shapes2]" time="0.061" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_diffconvs_model[True-False-ref_shapes3]" time="0.064" /><testcase classname="tests.torch.pruning.test_onnx_export" name="test_pruning_export_groupnorm_model" time="0.049" /><testcase classname="tests.torch.pruning.test_schedulers" name="test_baseline_scheduler" time="0.015" /><testcase classname="tests.torch.pruning.test_schedulers" name="test_exponential_scheduler" time="0.019" /><testcase classname="tests.torch.pruning.test_schedulers" name="test_exponential_with_bias" time="0.003" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_rounded_pruned_element_number[20-0.2-None-4]" time="0.001" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_rounded_pruned_element_number[20-0.2-8-4]" time="0.001" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_rounded_pruned_element_number[20-0.1-2-2]" time="0.001" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_rounded_pruned_element_number[20-0.1-5-0]" time="0.001" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_rounded_pruned_element_number[20-0.5-None-4]" time="0.001" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_bn_for_module_scope" time="0.026" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_first_pruned_layers[BigPruningTestModel-ref_first_module_names0]" time="0.026" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_first_pruned_layers[TestModelBranching-ref_first_module_names1]" time="0.023" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_last_pruned_layers[BigPruningTestModel-ref_last_module_names0]" time="0.026" /><testcase classname="tests.torch.pruning.test_utils" name="test_get_last_pruned_layers[TestModelBranching-ref_last_module_names1]" time="0.022" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_check_default_algo_params" time="0.015" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_valid_modules_replacement_and_pruning[False-False]" time="0.028" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_valid_modules_replacement_and_pruning[False-True]" time="0.029" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_valid_modules_replacement_and_pruning[True-False]" time="0.029" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_valid_modules_replacement_and_pruning[True-True]" time="0.030" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_pruning_masks_correctness[False-None-True-ref_masks0]" time="0.031" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_pruning_masks_correctness[True-None-True-ref_masks1]" time="0.031" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_pruning_masks_correctness[False-None-False-ref_masks2]" time="0.029" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_pruning_masks_correctness[True-None-False-ref_masks3]" time="0.029" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_pruning_masks_correctness[False-0.5-True-ref_masks4]" time="0.030" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_pruning_masks_correctness[False-0.5-False-ref_masks5]" time="0.029" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_pruning_masks_correctness[True-0.5-True-ref_masks6]" time="0.033" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_pruning_masks_correctness[True-0.5-False-ref_masks7]" time="0.034" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_applying_masks[False]" time="0.030" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_applying_masks[True]" time="0.031" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_applying_masks_for_bn_after_concat[False]" time="0.031" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_applying_masks_for_bn_after_concat[True]" time="0.031" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_zeroing_gradients[True]" time="0.036" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_zeroing_gradients[False]" time="0.035" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_calculation_of_flops[False-None-1315008]" time="0.029" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_calculation_of_flops[True-None-1492400]" time="0.030" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_calculation_of_flops[False-0.5-2367952]" time="0.030" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_calculation_of_flops[True-0.5-2380268]" time="0.032" /><testcase classname="tests.torch.pruning.filter_pruning.test_algo" name="test_clusters_for_multiple_forward" time="0.025" /><testcase classname="tests.torch.pruning.filter_pruning.test_flops_pruning" name="test_prune_flops_param[0.3-None-False-0.3]" time="0.015" /><testcase classname="tests.torch.pruning.filter_pruning.test_flops_pruning" name="test_prune_flops_param[None-0.3-True-0.3]" time="0.015" /><testcase classname="tests.torch.pruning.filter_pruning.test_flops_pruning" name="test_prune_flops_param[None-None-False-0.5]" time="0.016" /><testcase classname="tests.torch.pruning.filter_pruning.test_flops_pruning" name="test_both_targets_assert" time="0.011" /><testcase classname="tests.torch.pruning.filter_pruning.test_flops_pruning" name="test_init_params_for_flops_calculation[PruningTestModel-ref_params0]" time="0.015" /><testcase classname="tests.torch.pruning.filter_pruning.test_flops_pruning" name="test_flops_calulation_for_spec_layers[PruningTestWideModelConcat-False-671154176-402311168-ref_sizes0]" time="0.177" /><testcase classname="tests.torch.pruning.filter_pruning.test_flops_pruning" name="test_flops_calulation_for_spec_layers[PruningTestWideModelEltwise-False-268500992-157402112-ref_sizes1]" time="0.108" /><testcase classname="tests.torch.pruning.filter_pruning.test_flops_pruning" name="test_flops_calulation_for_spec_layers[PruningTestWideModelConcat-True-671154176-402578304-ref_sizes2]" time="0.248" /><testcase classname="tests.torch.pruning.filter_pruning.test_flops_pruning" name="test_flops_calulation_for_spec_layers[PruningTestWideModelEltwise-True-268500992-161036544-ref_sizes3]" time="0.148" /><testcase classname="tests.torch.pruning.filter_pruning.test_functions" name="test_norms[L1-input_tensor0-reference0]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_functions" name="test_norms[L2-input_tensor1-reference1]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_functions" name="test_norms[geometric_median-input_tensor2-reference2]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_functions" name="test_calculate_binary_mask[importance0-10.0-reference0]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers.TestApplyMasks" name="test_inplace_apply_filter_binary_mask[mask0-reference_weight0-reference_bias0]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers.TestApplyMasks" name="test_inplace_apply_filter_binary_mask[mask1-reference_weight1-reference_bias1]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers.TestApplyMasks" name="test_inplace_apply_filter_binary_mask[mask2-reference_weight2-reference_bias2]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers.TestApplyMasks" name="test_apply_filter_binary_mask[mask0-reference_weight0-reference_bias0]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers.TestApplyMasks" name="test_apply_filter_binary_mask[mask1-reference_weight1-reference_bias1]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers.TestApplyMasks" name="test_apply_filter_binary_mask[mask2-reference_weight2-reference_bias2]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers" name="test_can_infer_magnitude_pruned_conv[3-0]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers" name="test_can_infer_magnitude_pruned_conv[9-0]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers" name="test_can_infer_magnitude_pruned_conv[15-1]" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_layers" name="test_assert_broadcastable_mask_and_weight_shape" time="0.001" /><testcase classname="tests.torch.pruning.filter_pruning.test_set_pruning_rate" name="test_setting_pruning_rate[False-0.5-ref_pruning_rates0-0.5]" time="0.031" /><testcase classname="tests.torch.pruning.filter_pruning.test_set_pruning_rate" name="test_setting_pruning_rate[True-0.5-ref_pruning_rates1-0.5]" time="0.031" /><testcase classname="tests.torch.pruning.filter_pruning.test_set_pruning_rate" name="test_setting_pruning_rate[False-pruning_rate_to_set2-ref_pruning_rates2-0.69986]" time="0.031" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_all_int8]" time="0.106" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_all_weights_int8]" time="0.120" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_all_activations_int8]" time="0.286" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_bd_int8]" time="0.131" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_max_int4]" time="0.136" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_all_int8_requnt]" time="0.095" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_all_weights_int8_requnt]" time="0.125" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_all_activations_int8_requnt]" time="0.116" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_bd_int8_requnt]" time="0.124" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[vpu_max_int4_requnt]" time="0.314" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_on_synthetic_models[custom]" time="0.109" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_onnx_export_to_fake_quantize_with_adjust_pad" time="0.130" /><testcase classname="tests.torch.quantization.test_adjust_padding" name="test_adjust_padding_via_mixin_module" time="0.002" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantization_configs__with_defaults" time="0.022" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantization_configs__custom" time="0.018" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_can_load_quant_algo__with_defaults" time="0.024" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_can_create_quant_loss_and_scheduler" time="0.021" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_activation_quantizers_order_is_the_same__for_resnet50" time="0.093"><failure message="_pickle.PicklingError: Can't pickle &lt;function activation_quantizers_dumping_worker at 0x7fef88ad5a60&gt;: import of module 'test_algo_quantization' failed">tmp_path = PosixPath('/tmp/pytest-of-liubov/pytest-316/test_activation_quantizers_ord0'), runs_subprocess_in_precommit = None

    def test_activation_quantizers_order_is_the_same__for_resnet50(tmp_path, runs_subprocess_in_precommit):
        if not torch.cuda.is_available():
            pytest.skip("Skipping CUDA test cases for CPU only setups")
        config = get_empty_config(input_sample_sizes=[1, 3, 224, 224])
        config['compression'] = {'algorithm': 'quantization', "initializer": {"range": {"num_init_samples": 0}}}
        ngpus_per_node = torch.cuda.device_count()
    
&gt;       torch.multiprocessing.spawn(activation_quantizers_dumping_worker,
                                    nprocs=ngpus_per_node,
                                    args=(config, tmp_path),
                                    join=True)

quantization/test_algo_quantization.py:225: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:230: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
../../../miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:179: in start_processes
    process.start()
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/process.py:121: in start
    self._popen = self._Popen(self)
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/context.py:284: in _Popen
    return Popen(process_obj)
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/popen_spawn_posix.py:32: in __init__
    super().__init__(process_obj)
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/popen_fork.py:19: in __init__
    self._launch(process_obj)
../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/popen_spawn_posix.py:47: in _launch
    reduction.dump(process_obj, fp)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = &lt;SpawnProcess name='SpawnProcess-2' parent=4258 initial&gt;, file = &lt;_io.BytesIO object at 0x7feead6aa130&gt;, protocol = None

    def dump(obj, file, protocol=None):
        '''Replacement for pickle.dump() using ForkingPickler.'''
&gt;       ForkingPickler(file, protocol).dump(obj)
E       _pickle.PicklingError: Can't pickle &lt;function activation_quantizers_dumping_worker at 0x7fef88ad5a60&gt;: import of module 'test_algo_quantization' failed

../../../miniconda3/envs/pytorch/lib/python3.8/multiprocessing/reduction.py:60: PicklingError</failure></testcase><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_load_state_sets_initialized_flag" time="0.028" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizers_have_proper_narrow_range_set" time="0.021" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_hw_config_quantization_can_quantize_squeezenet[HWConfigType.CPU]" time="0.276" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_hw_config_quantization_can_quantize_squeezenet[HWConfigType.GPU]" time="0.274" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_hw_config_quantization_can_quantize_squeezenet[HWConfigType.VPU]" time="0.281" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantize_inputs" time="0.087" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf0-base_qconf0-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf1-base_qconf1-False]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf2-base_qconf2-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf3-base_qconf3-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf4-base_qconf4-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf5-base_qconf5-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf6-base_qconf6-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf7-base_qconf7-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf8-base_qconf8-False]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf9-base_qconf9-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf10-base_qconf10-False]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf11-base_qconf11-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf12-base_qconf12-False]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf13-base_qconf13-False]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf14-base_qconf14-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf15-base_qconf15-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf16-base_qconf16-True]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf17-base_qconf17-False]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantizer_ordering[requanting_qconf18-base_qconf18-False]" time="0.001" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantize_outputs" time="0.045" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_quantize_outputs_with_scope_overrides" time="0.041" /><testcase classname="tests.torch.quantization.test_algo_quantization" name="test_debug_mode" time="0.039" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[mobilenet_v2_device_VPU]" time="29.836" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[mobilenet_v2_device_VPU__ratio_0.4]" time="22.995" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[mobilenet_v2_device_VPU__eval_subset_ratio_0.4__ratio_0.4]" time="25.150" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[mobilenet_v2_device_VPU__eval_subset_ratio_0.4]" time="18.226" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[squeezenet1_1_device_VPU]" time="12.978" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[resnet50_device_VPU]" time="21.250" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[resnet50_device_VPU__iter_number_4__warmup_iter_number_2]" time="23.128" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[resnet50_device_VPU__ratio_0.4]" time="18.838" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[resnet50_device_VPU__eval_subset_ratio_0.4]" time="20.012" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[resnet50_device_VPU__eval_subset_ratio_0.4__ratio_0.4]" time="18.942" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[inception_v3_device_VPU__ratio_0.4]" time="33.183" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[inception_v3_device_VPU__eval_subset_ratio_0.4__with_ignored_scopes]" time="28.753" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[ssd_vgg_512_test_device_VPU__eval_subset_ratio_0.4]" time="22.957" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_autoq_precision_init[ssd_vgg_512_test_device_VPU__ratio_0.4]" time="18.995" /><testcase classname="tests.torch.quantization.test_autoq_precision_init" name="test_can_broadcast_initialized_precisions_in_distributed_mode" time="0.391"><failure message="torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with exit code 1">tmp_path = PosixPath('/tmp/pytest-of-liubov/pytest-316/test_can_broadcast_initialized0'), runs_subprocess_in_precommit = None

    def test_can_broadcast_initialized_precisions_in_distributed_mode(tmp_path, runs_subprocess_in_precommit):
        if not torch.cuda.is_available():
            pytest.skip("Skipping CUDA test cases for CPU only setups")
        config_builder = AutoQConfigBuilder(batch_size=2).for_trial()
        config = config_builder.build()
        ngpus_per_node = torch.cuda.device_count()
        config.world_size = ngpus_per_node
    
&gt;       torch.multiprocessing.spawn(precision_init_dumping_worker,
                                    nprocs=ngpus_per_node,
                                    args=(ngpus_per_node, config, tmp_path),
                                    join=True)

quantization/test_autoq_precision_init.py:185: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../../miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:230: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
../../../miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:188: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;torch.multiprocessing.spawn.ProcessContext object at 0x7fef1ee565e0&gt;, timeout = None

    def join(self, timeout=None):
        r"""
        Tries to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        for process in self.processes:
            if process.is_alive():
                process.terminate()
            process.join()
    
        # There won't be an error on the queue if the process crashed.
        failed_process = self.processes[error_index]
        if self.error_queues[error_index].empty():
            exitcode = self.processes[error_index].exitcode
            if exitcode &lt; 0:
                name = signal.Signals(-exitcode).name
                raise ProcessExitedException(
                    "process %d terminated with signal %s" %
                    (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name
                )
            else:
&gt;               raise ProcessExitedException(
                    "process %d terminated with exit code %d" %
                    (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode
                )
E               torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with exit code 1

../../../miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:139: ProcessExitedException</failure></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="1.856" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.230" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.173" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.058" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="1.847" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.229" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.172" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.004"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.853" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.230" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.172" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.846" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.229" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.172" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.058" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="1.850" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.230" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.173" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.058" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="1.846" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.229" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.172" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.856" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.233" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.178" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.058" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.849" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.231" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp16-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.177" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.023" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="0.794" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.080" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="0.776" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.079" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.022" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="0.768" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.082" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.061" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="0.759" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.081" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.061" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.768" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.079" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.773" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.079" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="0.767" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.081" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.061" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="0.760" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.081" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.061" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="0.774" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.079" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="0.774" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.079" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.022" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="0.767" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.081" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.061" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="0.761" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.082" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.062" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.780" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.088" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.071" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.781" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.087" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.071" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.022" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="0.773" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.090" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.071" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="0.766" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.089" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[signed-fp32-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.071" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="1.881" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.234" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.175" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="1.881" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.234" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.175" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.879" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.233" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.175" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.879" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.235" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.175" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="1.880" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.234" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.175" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="1.880" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.234" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.175" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.884" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.236" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.181" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.894" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.236" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.181" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="0.767" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.078" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="0.767" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.078" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="0.761" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.081" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="0.755" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.080" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.760" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.078" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.766" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.078" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="0.759" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.081" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="0.754" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.081" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="0.766" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.078" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="0.768" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.078" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.059" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="0.760" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.080" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="0.753" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.080" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.060" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.774" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.087" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.070" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.774" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.086" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.070" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.022" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="0.767" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.088" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.070" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="0.760" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.088" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_forward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.071" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.155" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.016" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="4.970" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.614" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.461" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.154" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.016" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="4.952" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.633" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.488" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.004"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="5.234" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.640" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.479" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.004"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="5.155" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.639" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.480" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.155" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.016" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="4.958" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.615" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.460" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.155" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.016" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="4.951" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.614" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.460" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.172" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.024" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="5.177" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.644" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.487" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.172" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.024" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="5.181" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.644" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp16-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.487" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="1.691" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.179" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.131" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="1.693" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.177" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.132" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.043" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="1.639" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.170" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.127" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="1.634" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.170" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.127" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="1.688" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.177" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.132" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="1.694" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.177" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.132" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.642" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.171" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.127" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.637" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.172" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.127" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="1.691" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.176" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.131" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="1.690" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.176" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.131" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.043" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="1.653" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.170" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.127" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="1.634" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.171" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.127" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.044" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="1.717" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.188" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.146" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.045" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="1.717" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.189" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.147" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.045" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.666" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.182" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.140" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.044" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.660" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.182" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[signed-fp32-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.140" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.157" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.016" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="5.017" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.622" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.466" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.158" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.016" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="5.015" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.622" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.468" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.004"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="5.214" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.647" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.485" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.004"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="5.212" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.647" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.485" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.157" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.016" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="5.018" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.623" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.466" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.157" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.016" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="5.016" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.622" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.466" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.175" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.024" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="5.254" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.653" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.496" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.176" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.024" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="5.330" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.683" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp16-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.516" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="1.684" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.176" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.131" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="1.684" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.176" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.130" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="1.632" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.169" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.126" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.041" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="1.627" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.169" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.126" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="1.680" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.176" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.131" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="1.686" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.176" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.131" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.636" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.170" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.126" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:165: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.628" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.170" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.127" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="1.685" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.175" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.131" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.042" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="1.684" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.175" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.130" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.043" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="1.630" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.169" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.126" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.041" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="1.626" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.169" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.126" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.043" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="1.708" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.188" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.145" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.044" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="1.708" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.188" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.145" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.045" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.655" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.181" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.140" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.043" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.649" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.181" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestSymmetric" name="test_quantize_symmetric_backward[unsigned-fp32-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.139" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.029" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="0.918" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.111" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.083" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.028" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="0.910" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.110" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.082" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.007"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.002"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="0.917" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.111" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.083" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.007"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.002"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="0.911" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.110" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.082" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.028" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="0.917" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.111" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.083" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.028" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="0.909" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.110" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.082" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.030" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="0.937" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.119" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.094" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.030" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.008" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="0.930" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.118" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp16-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.094" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.019" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="0.719" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.073" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.054" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.019" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="0.713" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.072" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.054" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="0.711" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.076" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.056" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="0.698" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.075" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.056" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.711" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.073" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.055" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.710" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.072" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.054" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="0.710" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.076" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.056" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="0.697" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.075" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.055" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.019" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="0.716" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.073" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.054" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.019" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="0.712" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.073" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.054" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="0.710" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.076" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.056" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.003" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="0.698" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.075" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.055" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.019" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.724" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.081" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.065" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.019" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.718" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.080" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.064" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.021" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="0.716" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.084" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.065" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.020" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="0.703" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.082" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_forward[fp32-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.064" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.083" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.012" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="2.751" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.341" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.255" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.084" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.012" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="2.621" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.320" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.239" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.006"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.002"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="2.682" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.327" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.245" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.007"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.002"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="2.620" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.319" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.239" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.082" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.012" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="2.684" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.328" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.245" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.080" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.012" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="2.619" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.320" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.239" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.001"><skipped type="pytest.skip" message="As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.">/home/liubov/nncf/tests/torch/quantization/test_functions.py:116: As of PyTorch 1.5, the 'abs' operation is not supported on CPU for half and thereforesymmetric quantize fails. Remove this once this is fixed in PyTorch.</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.092" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.015" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.014" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="2.743" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.343" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.262" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.088" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.014" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.014" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="2.687" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.335" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp16-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.257" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-8bit-[1-48-112-112]]" time="0.031" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-8bit-[1-96-28-28]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-8bit-[16-96-112-112]]" time="1.332" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-8bit-[16-192-28-28]]" time="0.136" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-8bit-[16-576-14-14]]" time="0.100" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-4bit-[1-48-112-112]]" time="0.032" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-4bit-[1-96-28-28]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-4bit-[16-96-112-112]]" time="1.325" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-4bit-[16-192-28-28]]" time="0.135" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cpu-4bit-[16-576-14-14]]" time="0.099" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-8bit-[1-48-112-112]]" time="0.031" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-8bit-[1-96-28-28]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-8bit-[1-288-14-14]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-8bit-[16-96-112-112]]" time="1.249" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-8bit-[16-192-28-28]]" time="0.128" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-8bit-[16-576-14-14]]" time="0.094" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-4bit-[1-48-112-112]]" time="0.030" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-4bit-[1-96-28-28]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-4bit-[1-288-14-14]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-4bit-[16-96-112-112]]" time="1.237" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-4bit-[16-192-28-28]]" time="0.127" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-single_scale-cuda-4bit-[16-576-14-14]]" time="0.094" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="1.327" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.136" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.101" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="1.327" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.135" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.100" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.251" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.128" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.094" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.005"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.001"><skipped type="pytest.skip" message="Same case as for single scale mode">/home/liubov/nncf/tests/torch/quantization/test_functions.py:282: Same case as for single scale mode</skipped></testcase><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.239" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.128" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-weights-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.094" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-8bit-[1-48-112-112]]" time="0.031" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-8bit-[1-96-28-28]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-8bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-8bit-[16-96-112-112]]" time="1.332" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-8bit-[16-192-28-28]]" time="0.136" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-8bit-[16-576-14-14]]" time="0.100" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-4bit-[1-48-112-112]]" time="0.031" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-4bit-[1-96-28-28]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-4bit-[1-288-14-14]]" time="0.005" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-4bit-[16-96-112-112]]" time="1.325" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-4bit-[16-192-28-28]]" time="0.135" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cpu-4bit-[16-576-14-14]]" time="0.099" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-8bit-[1-48-112-112]]" time="0.031" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-8bit-[1-96-28-28]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-8bit-[1-288-14-14]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-8bit-[16-96-112-112]]" time="1.248" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-8bit-[16-192-28-28]]" time="0.128" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-8bit-[16-576-14-14]]" time="0.093" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-4bit-[1-48-112-112]]" time="0.030" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-4bit-[1-96-28-28]]" time="0.006" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-4bit-[1-288-14-14]]" time="0.004" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-4bit-[16-96-112-112]]" time="1.237" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-4bit-[16-192-28-28]]" time="0.127" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-single_scale-cuda-4bit-[16-576-14-14]]" time="0.094" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-8bit-[1-48-112-112]]" time="0.033" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-8bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-8bit-[1-288-14-14]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-8bit-[16-96-112-112]]" time="1.355" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-8bit-[16-192-28-28]]" time="0.148" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-8bit-[16-576-14-14]]" time="0.114" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-4bit-[1-48-112-112]]" time="0.033" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-4bit-[1-288-14-14]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-4bit-[16-96-112-112]]" time="1.350" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-4bit-[16-192-28-28]]" time="0.146" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cpu-4bit-[16-576-14-14]]" time="0.113" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-8bit-[1-48-112-112]]" time="0.037" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-8bit-[1-96-28-28]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-8bit-[1-288-14-14]]" time="0.009" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-8bit-[16-96-112-112]]" time="1.241" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-8bit-[16-192-28-28]]" time="0.137" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-8bit-[16-576-14-14]]" time="0.105" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-4bit-[1-48-112-112]]" time="0.031" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-4bit-[1-96-28-28]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-4bit-[1-288-14-14]]" time="0.007" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-4bit-[16-96-112-112]]" time="1.223" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-4bit-[16-192-28-28]]" time="0.136" /><testcase classname="tests.torch.quantization.test_functions.TestParametrized.TestAsymmetric" name="test_quantize_asymmetric_backward[fp32-activation-per_channel_scale-cuda-4bit-[16-576-14-14]]" time="0.104" /><testcase classname="tests.torch.quantization.test_hawq_precision_init" name="test_hawq_precision_init[mobilenet_v2__staged]" time="18.936" /><testcase time="0.001" /></testsuite></testsuites>